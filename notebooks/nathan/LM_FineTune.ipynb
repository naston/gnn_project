{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82046ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4676a360",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1733039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/nodeproppred/arxiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB:   1%|          | 1/81 [00:19<25:30, 19.13s/it]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = PygNodePropPredDataset(name = 'ogbn-arxiv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f610624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sys import platform\n",
    "\n",
    "if platform == 'win32':\n",
    "    os.chdir('/'.join(os.getcwd().split('\\\\')[:-2]))\n",
    "else:\n",
    "    os.chdir('/'.join(os.getcwd().split('/')[:-2]))\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fd6d83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(cfg):\n",
    "    seeds = [cfg.seed] if cfg.seed is not None else range(1)\n",
    "    all_acc = []\n",
    "    for seed in seeds:\n",
    "        cfg.seed = seed\n",
    "        trainer = LMTrainer(cfg)\n",
    "        trainer.train()\n",
    "        acc = trainer.eval_and_save()\n",
    "        all_acc.append(acc)\n",
    "\n",
    "    if len(all_acc) > 1:\n",
    "        df = pd.DataFrame(all_acc)\n",
    "        for k, v in df.items():\n",
    "            print(f\"{k}: {v.mean():.4f} Â± {v.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51360fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'dataset': 'cora', 'device': 0, 'seed': None, 'lm': CfgNode({'model': CfgNode({'name': 'microsoft/deberta-base', 'feat_shrink': ''}), 'train': CfgNode({'batch_size': 9, 'grad_acc_steps': 1, 'lr': 2e-05, 'epochs': 4, 'warmup_epochs': 0.6, 'eval_patience': 50000, 'weight_decay': 0.0, 'dropout': 0.3, 'att_dropout': 0.1, 'cla_dropout': 0.4, 'use_gpt': False})}), 'text_type': 'raw'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc7ab430",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = update_cfg(cfg, 'cora', 'gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31fddced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'dataset': 'cora', 'device': 0, 'seed': 0, 'lm': CfgNode({'model': CfgNode({'name': 'microsoft/deberta-base', 'feat_shrink': ''}), 'train': CfgNode({'batch_size': 9, 'grad_acc_steps': 1, 'lr': 2e-05, 'epochs': 4, 'warmup_epochs': 0.6, 'eval_patience': 50000, 'weight_decay': 0.0, 'dropout': 0.3, 'att_dropout': 0.1, 'cla_dropout': 0.4, 'use_gpt': False})}), 'text_type': 'gpt'})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca761732",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25aedfb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc\n",
      "tokenizer\n",
      "<class 'torch.utils.data.dataset.Subset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of parameters: 138607111\n",
      "Start running train at 11-13 13:40:36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\stare\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 1:39:05, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM saved to prt_lm/cora/microsoft/deberta-base-seed0.ckpt\n",
      "Finished running train at 11-13 15:19:55, running time = 1.66h.\n",
      "Start running eval_and_save at 11-13 15:19:55\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LM] TrainAcc: 0.9526, ValAcc: 0.8026, TestAcc: 0.7970\n",
      "\n",
      "Finished running eval_and_save at 11-13 15:29:20, running time = 9.41min.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Paull\\github\\personal\\gnn_project\\src\\lm_trainer.py:275: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"y_true\": torch.tensor(labels).view(-1, 1),\n"
     ]
    }
   ],
   "source": [
    "run(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067380a9",
   "metadata": {},
   "source": [
    "# GPT Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b27510d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = update_cfg(cfg, 'cora', 'gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8054cd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CfgNode({'dataset': 'cora', 'device': 0, 'seed': None, 'lm': CfgNode({'model': CfgNode({'name': 'microsoft/deberta-base', 'feat_shrink': ''}), 'train': CfgNode({'batch_size': 9, 'grad_acc_steps': 1, 'lr': 2e-05, 'epochs': 4, 'warmup_epochs': 0.6, 'eval_patience': 50000, 'weight_decay': 0.0, 'dropout': 0.3, 'att_dropout': 0.1, 'cla_dropout': 0.4, 'use_gpt': False})}), 'text_type': 'gpt'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e276e9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new load\n",
      "<class 'torch.utils.data.dataset.Subset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of parameters: 138607111\n",
      "Start running train at 11-13 16:34:35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\envs\\stare\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 17:03, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LM saved to prt_lm/cora/microsoft/deberta-base-seed0.ckpt\n",
      "Finished running train at 11-13 16:51:52, running time = 17.28min.\n",
      "Start running eval_and_save at 11-13 16:51:52\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LM] TrainAcc: 0.9083, ValAcc: 0.7823, TestAcc: 0.7970\n",
      "\n",
      "Finished running eval_and_save at 11-13 16:57:16, running time = 5.40min.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nathan Paull\\github\\personal\\gnn_project\\src\\lm_trainer.py:278: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"y_true\": torch.tensor(labels).view(-1, 1),\n"
     ]
    }
   ],
   "source": [
    "run(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc085a98",
   "metadata": {},
   "source": [
    "# Ignore, just testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbc5d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babcfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LM_pred_path = './prt_lm/cora/microsoft/deberta-base-raw-text.pred'\n",
    "preds = np.array(\n",
    "                np.memmap(LM_pred_path, mode='r',\n",
    "                          dtype=np.float16,\n",
    "                          shape=(2708, 7)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f86d8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 5, 4, ..., 1, 0, 2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce26b449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â­âââââââââââââââââââââââââââââââ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> âââââââââââââââââââââââââââââââââ®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1 trainer.data                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">NameError: </span>name <span style=\"color: #008000; text-decoration-color: #008000\">'trainer'</span> is not defined\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ­â\u001b[0m\u001b[31mââââââââââââââââââââââââââââââ\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâââââââââââââââââââââââââââââââ\u001b[0m\u001b[31mââ®\u001b[0m\n",
       "\u001b[31mâ\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m                                                                                                  \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m \u001b[31mâ± \u001b[0m1 trainer.data                                                                                 \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31mâ\u001b[0m\n",
       "\u001b[31mâ°âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ¯\u001b[0m\n",
       "\u001b[1;91mNameError: \u001b[0mname \u001b[32m'trainer'\u001b[0m is not defined\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c72d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc\n",
      "tokenizer\n",
      "<class 'torch.utils.data.dataset.Subset'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of parameters: 138607111\n"
     ]
    }
   ],
   "source": [
    "t_test = LMTrainer(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b02a200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 5, 4,  ..., 1, 0, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test.data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "114af9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "from torch_geometric.datasets import Planetoid, Actor\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5123e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3b6bec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora[0].y"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0a480efe",
   "metadata": {},
   "source": [
    "This seems to tell me that the planetoid data and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de54ee4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Planetoid('dataset', 'cora',\n",
    "                        transform=NormalizeFeatures())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d668f821",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 4,  ..., 3, 3, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88eb306f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708], num_nodes=2708, train_id=[1624], val_id=[542], test_id=[542])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8c8ff63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6], dtype=int64),\n",
       " array([351, 217, 418, 818, 426, 298, 180], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dataset[0].y.numpy(),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "703dfdcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6], dtype=int64),\n",
       " array([298, 418, 818, 426, 217, 180, 351], dtype=int64))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(t_test.data.y.numpy(),return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e016c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05a83bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cora_tape():\n",
    "    text = []\n",
    "    #files = os.listdir('./data/Cora_TAPE')\n",
    "    #return files\n",
    "    for i in range(2708):\n",
    "        with open('./data/Cora_TAPE/'+str(i)+'.json') as f:\n",
    "            data = json.load(f)\n",
    "            text.append(data['choices'][0]['message']['content'])\n",
    "        f.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dd69734",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = load_cora_tape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9976ca9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'0.json' in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cba20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
