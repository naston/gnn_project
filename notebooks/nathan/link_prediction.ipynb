{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, Actor\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from copy import deepcopy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/'.join(os.getcwd().split('/')[:-2]))\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cora model:\n",
    "cora = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(cora[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cora.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.citeseer.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# CiteSeer model:\n",
    "citeseer = Planetoid(root='data/Planetoid', name='CiteSeer', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(citeseer[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=19717, num_edges=71822,\n",
       "      ndata_schemes={'x': Scheme(shape=(500,), dtype=torch.float32), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'y': Scheme(shape=(), dtype=torch.int64)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.x\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.tx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.allx\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.y\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ty\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.ally\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.graph\n",
      "Downloading https://github.com/kimiyoung/planetoid/raw/master/data/ind.pubmed.test.index\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# PubMed model:\n",
    "pubmed = Planetoid(root='data/Planetoid', name='PubMed', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(pubmed[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32)\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6889550089836121\n",
      "In epoch 10, loss: 0.6518698334693909\n",
      "In epoch 15, loss: 0.5650844573974609\n",
      "In epoch 20, loss: 0.5231456756591797\n",
      "In epoch 25, loss: 0.48154327273368835\n",
      "In epoch 30, loss: 0.45232367515563965\n",
      "In epoch 35, loss: 0.42372268438339233\n",
      "In epoch 40, loss: 0.3935740292072296\n",
      "In epoch 45, loss: 0.36289507150650024\n",
      "In epoch 50, loss: 0.331249862909317\n",
      "In epoch 55, loss: 0.2984686493873596\n",
      "In epoch 60, loss: 0.26581239700317383\n",
      "In epoch 65, loss: 0.23318511247634888\n",
      "In epoch 70, loss: 0.20120082795619965\n",
      "In epoch 75, loss: 0.1697053611278534\n",
      "In epoch 80, loss: 0.139704167842865\n",
      "In epoch 85, loss: 0.11153599619865417\n",
      "In epoch 90, loss: 0.08590317517518997\n",
      "In epoch 95, loss: 0.06340423971414566\n",
      "In epoch 100, loss: 0.044946979731321335\n",
      "AUC 0.8463763167943218\n",
      "In epoch 105, loss: 0.030565321445465088\n",
      "In epoch 110, loss: 0.020160149782896042\n",
      "In epoch 115, loss: 0.013097207993268967\n",
      "In epoch 120, loss: 0.00856858305633068\n",
      "In epoch 125, loss: 0.005739990156143904\n",
      "In epoch 130, loss: 0.003980258945375681\n",
      "In epoch 135, loss: 0.0028719864785671234\n",
      "In epoch 140, loss: 0.0021710768342018127\n",
      "In epoch 145, loss: 0.0017122066346928477\n",
      "In epoch 150, loss: 0.0013997583882883191\n",
      "In epoch 155, loss: 0.0011788620613515377\n",
      "In epoch 160, loss: 0.001016520895063877\n",
      "In epoch 165, loss: 0.0008932119235396385\n",
      "In epoch 170, loss: 0.0007964333053678274\n",
      "In epoch 175, loss: 0.0007181782275438309\n",
      "In epoch 180, loss: 0.0006535244756378233\n",
      "In epoch 185, loss: 0.0005990696954540908\n",
      "In epoch 190, loss: 0.0005524686421267688\n",
      "In epoch 195, loss: 0.0005120703135617077\n",
      "In epoch 200, loss: 0.0004766521160490811\n",
      "AUC 0.8398014420161272\n",
      "In epoch 205, loss: 0.0004453294677659869\n",
      "In epoch 210, loss: 0.0004174041678197682\n",
      "In epoch 215, loss: 0.0003923221956938505\n",
      "In epoch 220, loss: 0.0003696661442518234\n",
      "In epoch 225, loss: 0.0003490938397590071\n",
      "In epoch 230, loss: 0.00033033525687642395\n",
      "In epoch 235, loss: 0.00031317409593611956\n",
      "In epoch 240, loss: 0.00029742246260866523\n",
      "In epoch 245, loss: 0.0002829151344485581\n",
      "In epoch 250, loss: 0.0002695249277167022\n",
      "In epoch 255, loss: 0.00025712396018207073\n",
      "In epoch 260, loss: 0.00024561258032917976\n",
      "In epoch 265, loss: 0.00023490645980928093\n",
      "In epoch 270, loss: 0.0002249220706289634\n",
      "In epoch 275, loss: 0.00021559413289651275\n",
      "In epoch 280, loss: 0.00020686736388597637\n",
      "In epoch 285, loss: 0.00019868845993187279\n",
      "In epoch 290, loss: 0.00019101005455013365\n",
      "In epoch 295, loss: 0.00018378734239377081\n",
      "In epoch 300, loss: 0.00017698740703053772\n",
      "AUC 0.8400575009546056\n",
      "In epoch 305, loss: 0.00017057389777619392\n",
      "In epoch 310, loss: 0.00016452146519441158\n",
      "In epoch 315, loss: 0.00015879656712058932\n",
      "In epoch 320, loss: 0.0001533826725790277\n",
      "In epoch 325, loss: 0.00014825069229118526\n",
      "In epoch 330, loss: 0.00014338297478388995\n",
      "In epoch 335, loss: 0.0001387604424962774\n",
      "In epoch 340, loss: 0.0001343663316220045\n",
      "In epoch 345, loss: 0.0001301856100326404\n",
      "In epoch 350, loss: 0.00012620452616829425\n",
      "In epoch 355, loss: 0.00012241014337632805\n",
      "In epoch 360, loss: 0.00011878977966262028\n",
      "In epoch 365, loss: 0.00011533170618349686\n",
      "In epoch 370, loss: 0.00011202715541003272\n",
      "In epoch 375, loss: 0.00010886652307817712\n",
      "In epoch 380, loss: 0.00010584248957457021\n",
      "In epoch 385, loss: 0.00010294739331584424\n",
      "In epoch 390, loss: 0.00010017298336606473\n",
      "In epoch 395, loss: 9.751366451382637e-05\n",
      "In epoch 400, loss: 9.49619643506594e-05\n",
      "AUC 0.8402309022708385\n",
      "In epoch 405, loss: 9.251206211047247e-05\n",
      "In epoch 410, loss: 9.015925752464682e-05\n",
      "In epoch 415, loss: 8.789755520410836e-05\n",
      "In epoch 420, loss: 8.572185470256954e-05\n",
      "In epoch 425, loss: 8.3628372522071e-05\n",
      "In epoch 430, loss: 8.161203004419804e-05\n",
      "In epoch 435, loss: 7.966950943227857e-05\n",
      "In epoch 440, loss: 7.779442967148498e-05\n",
      "In epoch 445, loss: 7.598686352139339e-05\n",
      "In epoch 450, loss: 7.424272189382464e-05\n",
      "In epoch 455, loss: 7.255761738633737e-05\n",
      "In epoch 460, loss: 7.093008753145114e-05\n",
      "In epoch 465, loss: 6.935801502550021e-05\n",
      "In epoch 470, loss: 6.783895514672622e-05\n",
      "In epoch 475, loss: 6.637004116782919e-05\n",
      "In epoch 480, loss: 6.494909030152485e-05\n",
      "In epoch 485, loss: 6.357424717862159e-05\n",
      "In epoch 490, loss: 6.224466051207855e-05\n",
      "In epoch 495, loss: 6.095651042414829e-05\n",
      "In epoch 500, loss: 5.970855272607878e-05\n",
      "AUC 0.8402201208418499\n",
      "In epoch 505, loss: 5.850009256391786e-05\n",
      "In epoch 510, loss: 5.73289034946356e-05\n",
      "In epoch 515, loss: 5.6191947805928066e-05\n",
      "In epoch 520, loss: 5.509029870154336e-05\n",
      "In epoch 525, loss: 5.4020623792894185e-05\n",
      "In epoch 530, loss: 5.2982326451456174e-05\n",
      "In epoch 535, loss: 5.1973962399642915e-05\n",
      "In epoch 540, loss: 5.099427289678715e-05\n",
      "In epoch 545, loss: 5.004241393180564e-05\n",
      "In epoch 550, loss: 4.911722135148011e-05\n",
      "In epoch 555, loss: 4.821643597097136e-05\n",
      "In epoch 560, loss: 4.733943933388218e-05\n",
      "In epoch 565, loss: 4.648617687053047e-05\n",
      "In epoch 570, loss: 4.5655822759727016e-05\n",
      "In epoch 575, loss: 4.484816963667981e-05\n",
      "In epoch 580, loss: 4.406135849421844e-05\n",
      "In epoch 585, loss: 4.3295938667142764e-05\n",
      "In epoch 590, loss: 4.2550236685201526e-05\n",
      "In epoch 595, loss: 4.182348129688762e-05\n",
      "In epoch 600, loss: 4.111452290089801e-05\n",
      "AUC 0.8402282069135913\n",
      "In epoch 605, loss: 4.042407454107888e-05\n",
      "In epoch 610, loss: 3.9750957512296736e-05\n",
      "In epoch 615, loss: 3.909559745807201e-05\n",
      "In epoch 620, loss: 3.845578248728998e-05\n",
      "In epoch 625, loss: 3.78322001779452e-05\n",
      "In epoch 630, loss: 3.722416659002192e-05\n",
      "In epoch 635, loss: 3.663073948700912e-05\n",
      "In epoch 640, loss: 3.605132587836124e-05\n",
      "In epoch 645, loss: 3.548589302226901e-05\n",
      "In epoch 650, loss: 3.4933764254674315e-05\n",
      "In epoch 655, loss: 3.4394590329611674e-05\n",
      "In epoch 660, loss: 3.386769458302297e-05\n",
      "In epoch 665, loss: 3.3352614991599694e-05\n",
      "In epoch 670, loss: 3.284977356088348e-05\n",
      "In epoch 675, loss: 3.23579806718044e-05\n",
      "In epoch 680, loss: 3.187700713169761e-05\n",
      "In epoch 685, loss: 3.140744593110867e-05\n",
      "In epoch 690, loss: 3.0947794584790245e-05\n",
      "In epoch 695, loss: 3.0498496926156804e-05\n",
      "In epoch 700, loss: 3.0059038181207143e-05\n",
      "AUC 0.8402538128074392\n",
      "In epoch 705, loss: 2.9628916308865882e-05\n",
      "In epoch 710, loss: 2.9207409170339815e-05\n",
      "In epoch 715, loss: 2.8795226171496324e-05\n",
      "In epoch 720, loss: 2.8391987143550068e-05\n",
      "In epoch 725, loss: 2.799728827085346e-05\n",
      "In epoch 730, loss: 2.7610181859927252e-05\n",
      "In epoch 735, loss: 2.723134275584016e-05\n",
      "In epoch 740, loss: 2.6860305297304876e-05\n",
      "In epoch 745, loss: 2.649605812621303e-05\n",
      "In epoch 750, loss: 2.6139083274756558e-05\n",
      "In epoch 755, loss: 2.5789144274313003e-05\n",
      "In epoch 760, loss: 2.5445729988859966e-05\n",
      "In epoch 765, loss: 2.5109382477239706e-05\n",
      "In epoch 770, loss: 2.4779767045401968e-05\n",
      "In epoch 775, loss: 2.4456885512336157e-05\n",
      "In epoch 780, loss: 2.4139293600455858e-05\n",
      "In epoch 785, loss: 2.3828604753362015e-05\n",
      "In epoch 790, loss: 2.352356750634499e-05\n",
      "In epoch 795, loss: 2.322480213479139e-05\n",
      "In epoch 800, loss: 2.293145917064976e-05\n",
      "AUC 0.8402524651288157\n",
      "In epoch 805, loss: 2.264391878270544e-05\n",
      "In epoch 810, loss: 2.236106593045406e-05\n",
      "In epoch 815, loss: 2.2083906515035778e-05\n",
      "In epoch 820, loss: 2.1811742044519633e-05\n",
      "In epoch 825, loss: 2.154393405362498e-05\n",
      "In epoch 830, loss: 2.1281157387420535e-05\n",
      "In epoch 835, loss: 2.102324469888117e-05\n",
      "In epoch 840, loss: 2.0769670300069265e-05\n",
      "In epoch 845, loss: 2.052089257631451e-05\n",
      "In epoch 850, loss: 2.0276373106753454e-05\n",
      "In epoch 855, loss: 2.0036746718687937e-05\n",
      "In epoch 860, loss: 1.9801083908532746e-05\n",
      "In epoch 865, loss: 1.9568862626329064e-05\n",
      "In epoch 870, loss: 1.9341188817634247e-05\n",
      "In epoch 875, loss: 1.911676190502476e-05\n",
      "In epoch 880, loss: 1.889692066470161e-05\n",
      "In epoch 885, loss: 1.868041363195516e-05\n",
      "In epoch 890, loss: 1.846759914769791e-05\n",
      "In epoch 895, loss: 1.8258220734423958e-05\n",
      "In epoch 900, loss: 1.8052714949590154e-05\n",
      "AUC 0.8402910985826912\n",
      "In epoch 905, loss: 1.785043605195824e-05\n",
      "In epoch 910, loss: 1.765119486663025e-05\n",
      "In epoch 915, loss: 1.7455686247558333e-05\n",
      "In epoch 920, loss: 1.726300615700893e-05\n",
      "In epoch 925, loss: 1.70738512679236e-05\n",
      "In epoch 930, loss: 1.6886882804101333e-05\n",
      "In epoch 935, loss: 1.6703248547855765e-05\n",
      "In epoch 940, loss: 1.65230012498796e-05\n",
      "In epoch 945, loss: 1.6345329640898854e-05\n",
      "In epoch 950, loss: 1.6170299204532057e-05\n",
      "In epoch 955, loss: 1.5998122762539424e-05\n",
      "In epoch 960, loss: 1.5828940377105027e-05\n",
      "In epoch 965, loss: 1.5662126315874048e-05\n",
      "In epoch 970, loss: 1.549794069433119e-05\n",
      "In epoch 975, loss: 1.5336263459175825e-05\n",
      "In epoch 980, loss: 1.5177245586528443e-05\n",
      "In epoch 985, loss: 1.502033592259977e-05\n",
      "In epoch 990, loss: 1.4865585399093106e-05\n",
      "In epoch 995, loss: 1.4713687050971203e-05\n",
      "In epoch 1000, loss: 1.4563878721673973e-05\n",
      "AUC 0.8402277576873834\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='pool')\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6896283626556396\n",
      "In epoch 10, loss: 0.6560142040252686\n",
      "In epoch 15, loss: 0.5743506550788879\n",
      "In epoch 20, loss: 0.5148227214813232\n",
      "In epoch 25, loss: 0.47026118636131287\n",
      "In epoch 30, loss: 0.4502517879009247\n",
      "In epoch 35, loss: 0.42443642020225525\n",
      "In epoch 40, loss: 0.4016067683696747\n",
      "In epoch 45, loss: 0.37799903750419617\n",
      "In epoch 50, loss: 0.3537021279335022\n",
      "In epoch 55, loss: 0.3277355432510376\n",
      "In epoch 60, loss: 0.3009139597415924\n",
      "In epoch 65, loss: 0.2736055850982666\n",
      "In epoch 70, loss: 0.24635633826255798\n",
      "In epoch 75, loss: 0.21949876844882965\n",
      "In epoch 80, loss: 0.19362212717533112\n",
      "In epoch 85, loss: 0.1683475822210312\n",
      "In epoch 90, loss: 0.14423726499080658\n",
      "In epoch 95, loss: 0.12137138843536377\n",
      "In epoch 100, loss: 0.10013372451066971\n",
      "AUC 0.8168900069630063\n",
      "In epoch 105, loss: 0.08049999922513962\n",
      "In epoch 110, loss: 0.06301059573888779\n",
      "In epoch 115, loss: 0.04807618632912636\n",
      "In epoch 120, loss: 0.03584400564432144\n",
      "In epoch 125, loss: 0.026213455945253372\n",
      "In epoch 130, loss: 0.018935998901724815\n",
      "In epoch 135, loss: 0.013588742353022099\n",
      "In epoch 140, loss: 0.00978713296353817\n",
      "In epoch 145, loss: 0.007112810388207436\n",
      "In epoch 150, loss: 0.0052453200332820415\n",
      "In epoch 155, loss: 0.003945310600101948\n",
      "In epoch 160, loss: 0.0030429984908550978\n",
      "In epoch 165, loss: 0.002411972265690565\n",
      "In epoch 170, loss: 0.0019640596583485603\n",
      "In epoch 175, loss: 0.001639214693568647\n",
      "In epoch 180, loss: 0.001397729036398232\n",
      "In epoch 185, loss: 0.0012128123780712485\n",
      "In epoch 190, loss: 0.00106749904807657\n",
      "In epoch 195, loss: 0.0009506579372100532\n",
      "In epoch 200, loss: 0.0008550189668312669\n",
      "AUC 0.8018544057860335\n",
      "In epoch 205, loss: 0.0007753268000669777\n",
      "In epoch 210, loss: 0.0007080209907144308\n",
      "In epoch 215, loss: 0.0006503814365714788\n",
      "In epoch 220, loss: 0.0006004833849146962\n",
      "In epoch 225, loss: 0.0005568785709328949\n",
      "In epoch 230, loss: 0.0005184568581171334\n",
      "In epoch 235, loss: 0.0004843534843530506\n",
      "In epoch 240, loss: 0.0004539043002296239\n",
      "In epoch 245, loss: 0.00042646622750908136\n",
      "In epoch 250, loss: 0.0004016720922663808\n",
      "In epoch 255, loss: 0.0003791310009546578\n",
      "In epoch 260, loss: 0.00035857033799402416\n",
      "In epoch 265, loss: 0.0003397477848920971\n",
      "In epoch 270, loss: 0.0003224519023206085\n",
      "In epoch 275, loss: 0.0003065112978219986\n",
      "In epoch 280, loss: 0.00029180265846662223\n",
      "In epoch 285, loss: 0.0002781777293421328\n",
      "In epoch 290, loss: 0.0002655019925441593\n",
      "In epoch 295, loss: 0.00025369483046233654\n",
      "In epoch 300, loss: 0.00024266862601507455\n",
      "AUC 0.8032829451270187\n",
      "In epoch 305, loss: 0.0002323721128050238\n",
      "In epoch 310, loss: 0.00022274706861935556\n",
      "In epoch 315, loss: 0.00021371616458054632\n",
      "In epoch 320, loss: 0.0002052313939202577\n",
      "In epoch 325, loss: 0.00019725608581211418\n",
      "In epoch 330, loss: 0.00018975193961523473\n",
      "In epoch 335, loss: 0.0001826928200898692\n",
      "In epoch 340, loss: 0.0001760425657266751\n",
      "In epoch 345, loss: 0.00016975983453448862\n",
      "In epoch 350, loss: 0.00016381485329475254\n",
      "In epoch 355, loss: 0.00015818544488865882\n",
      "In epoch 360, loss: 0.00015285417612176389\n",
      "In epoch 365, loss: 0.00014780105266254395\n",
      "In epoch 370, loss: 0.00014299996837507933\n",
      "In epoch 375, loss: 0.00013843645865563303\n",
      "In epoch 380, loss: 0.00013409694656729698\n",
      "In epoch 385, loss: 0.00012996795703656971\n",
      "In epoch 390, loss: 0.0001260300778085366\n",
      "In epoch 395, loss: 0.00012227206025272608\n",
      "In epoch 400, loss: 0.00011868090950883925\n",
      "AUC 0.8038058444329642\n",
      "In epoch 405, loss: 0.00011525196896400303\n",
      "In epoch 410, loss: 0.0001119672306231223\n",
      "In epoch 415, loss: 0.00010882822243729606\n",
      "In epoch 420, loss: 0.00010582010872894898\n",
      "In epoch 425, loss: 0.00010294105595676228\n",
      "In epoch 430, loss: 0.00010018031753133982\n",
      "In epoch 435, loss: 9.753242193255574e-05\n",
      "In epoch 440, loss: 9.499250154476613e-05\n",
      "In epoch 445, loss: 9.25541971810162e-05\n",
      "In epoch 450, loss: 9.02084429981187e-05\n",
      "In epoch 455, loss: 8.795198664302006e-05\n",
      "In epoch 460, loss: 8.578064444009215e-05\n",
      "In epoch 465, loss: 8.368585258722305e-05\n",
      "In epoch 470, loss: 8.166850602719933e-05\n",
      "In epoch 475, loss: 7.972445018822327e-05\n",
      "In epoch 480, loss: 7.785114576108754e-05\n",
      "In epoch 485, loss: 7.604630809510127e-05\n",
      "In epoch 490, loss: 7.430582627421245e-05\n",
      "In epoch 495, loss: 7.262616418302059e-05\n",
      "In epoch 500, loss: 7.100500079104677e-05\n",
      "AUC 0.8043107746905955\n",
      "In epoch 505, loss: 6.943749758647755e-05\n",
      "In epoch 510, loss: 6.792042404413223e-05\n",
      "In epoch 515, loss: 6.645321991527453e-05\n",
      "In epoch 520, loss: 6.503392796730623e-05\n",
      "In epoch 525, loss: 6.366078741848469e-05\n",
      "In epoch 530, loss: 6.233099702512845e-05\n",
      "In epoch 535, loss: 6.104380736360326e-05\n",
      "In epoch 540, loss: 5.979786874377169e-05\n",
      "In epoch 545, loss: 5.859034354216419e-05\n",
      "In epoch 550, loss: 5.741906716139056e-05\n",
      "In epoch 555, loss: 5.628177314065397e-05\n",
      "In epoch 560, loss: 5.517870158655569e-05\n",
      "In epoch 565, loss: 5.4108288168208674e-05\n",
      "In epoch 570, loss: 5.306919410941191e-05\n",
      "In epoch 575, loss: 5.2060309826629236e-05\n",
      "In epoch 580, loss: 5.107886318000965e-05\n",
      "In epoch 585, loss: 5.0123580876970664e-05\n",
      "In epoch 590, loss: 4.9195659812539816e-05\n",
      "In epoch 595, loss: 4.829353929380886e-05\n",
      "In epoch 600, loss: 4.741638258565217e-05\n",
      "AUC 0.804478785292334\n",
      "In epoch 605, loss: 4.6562901843572035e-05\n",
      "In epoch 610, loss: 4.573333353619091e-05\n",
      "In epoch 615, loss: 4.492590596782975e-05\n",
      "In epoch 620, loss: 4.414022987475619e-05\n",
      "In epoch 625, loss: 4.3374857341405004e-05\n",
      "In epoch 630, loss: 4.262938455212861e-05\n",
      "In epoch 635, loss: 4.190400068182498e-05\n",
      "In epoch 640, loss: 4.119625737075694e-05\n",
      "In epoch 645, loss: 4.050618372275494e-05\n",
      "In epoch 650, loss: 3.983412898378447e-05\n",
      "In epoch 655, loss: 3.9177997678052634e-05\n",
      "In epoch 660, loss: 3.8538699300261214e-05\n",
      "In epoch 665, loss: 3.791440758504905e-05\n",
      "In epoch 670, loss: 3.730575554072857e-05\n",
      "In epoch 675, loss: 3.671174272312783e-05\n",
      "In epoch 680, loss: 3.613145963754505e-05\n",
      "In epoch 685, loss: 3.5564706195145845e-05\n",
      "In epoch 690, loss: 3.501027822494507e-05\n",
      "In epoch 695, loss: 3.446927075856365e-05\n",
      "In epoch 700, loss: 3.3940963476197794e-05\n",
      "AUC 0.8046162485119382\n",
      "In epoch 705, loss: 3.3425527362851426e-05\n",
      "In epoch 710, loss: 3.292119799880311e-05\n",
      "In epoch 715, loss: 3.242848833906464e-05\n",
      "In epoch 720, loss: 3.194677992723882e-05\n",
      "In epoch 725, loss: 3.147513052681461e-05\n",
      "In epoch 730, loss: 3.101356924162246e-05\n",
      "In epoch 735, loss: 3.0562190659111366e-05\n",
      "In epoch 740, loss: 3.0120510928099975e-05\n",
      "In epoch 745, loss: 2.9688018912565894e-05\n",
      "In epoch 750, loss: 2.9265043849591166e-05\n",
      "In epoch 755, loss: 2.885106732719578e-05\n",
      "In epoch 760, loss: 2.8446089345379733e-05\n",
      "In epoch 765, loss: 2.8049067623214796e-05\n",
      "In epoch 770, loss: 2.7659967599902302e-05\n",
      "In epoch 775, loss: 2.7278911147732288e-05\n",
      "In epoch 780, loss: 2.6906041966867633e-05\n",
      "In epoch 785, loss: 2.6541285478742793e-05\n",
      "In epoch 790, loss: 2.6183721274719574e-05\n",
      "In epoch 795, loss: 2.5832148821791634e-05\n",
      "In epoch 800, loss: 2.5487881430308335e-05\n",
      "AUC 0.8047878529233394\n",
      "In epoch 805, loss: 2.515044980100356e-05\n",
      "In epoch 810, loss: 2.4819260943331756e-05\n",
      "In epoch 815, loss: 2.449453495501075e-05\n",
      "In epoch 820, loss: 2.4175780708901584e-05\n",
      "In epoch 825, loss: 2.386315281910356e-05\n",
      "In epoch 830, loss: 2.3556543965241872e-05\n",
      "In epoch 835, loss: 2.3255801352206618e-05\n",
      "In epoch 840, loss: 2.2960464775678702e-05\n",
      "In epoch 845, loss: 2.267138916067779e-05\n",
      "In epoch 850, loss: 2.238734668935649e-05\n",
      "In epoch 855, loss: 2.2108317352831364e-05\n",
      "In epoch 860, loss: 2.1834546714671887e-05\n",
      "In epoch 865, loss: 2.156566370103974e-05\n",
      "In epoch 870, loss: 2.1301744709489867e-05\n",
      "In epoch 875, loss: 2.1042438675067388e-05\n",
      "In epoch 880, loss: 2.0787691028090194e-05\n",
      "In epoch 885, loss: 2.0537505406537093e-05\n",
      "In epoch 890, loss: 2.029117604251951e-05\n",
      "In epoch 895, loss: 2.0048872102051973e-05\n",
      "In epoch 900, loss: 1.9811015590676107e-05\n",
      "AUC 0.8049414882864266\n",
      "In epoch 905, loss: 1.957712447619997e-05\n",
      "In epoch 910, loss: 1.93473206309136e-05\n",
      "In epoch 915, loss: 1.9121207515127026e-05\n",
      "In epoch 920, loss: 1.889925442810636e-05\n",
      "In epoch 925, loss: 1.86805864359485e-05\n",
      "In epoch 930, loss: 1.846586565079633e-05\n",
      "In epoch 935, loss: 1.8254419046570547e-05\n",
      "In epoch 940, loss: 1.8046990589937195e-05\n",
      "In epoch 945, loss: 1.7842901797848754e-05\n",
      "In epoch 950, loss: 1.764209446264431e-05\n",
      "In epoch 955, loss: 1.7444632248952985e-05\n",
      "In epoch 960, loss: 1.7249943994102068e-05\n",
      "In epoch 965, loss: 1.7059192032320425e-05\n",
      "In epoch 970, loss: 1.6871197658474557e-05\n",
      "In epoch 975, loss: 1.668632285145577e-05\n",
      "In epoch 980, loss: 1.6504654922755435e-05\n",
      "In epoch 985, loss: 1.6325620890711434e-05\n",
      "In epoch 990, loss: 1.6149593648151495e-05\n",
      "In epoch 995, loss: 1.5976209397194907e-05\n",
      "In epoch 1000, loss: 1.580540083523374e-05\n",
      "AUC 0.8050519979335594\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### LSTM Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='lstm')\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6888569593429565\n",
      "In epoch 10, loss: 0.6576717495918274\n",
      "In epoch 15, loss: 0.5815128087997437\n",
      "In epoch 20, loss: 0.5191725492477417\n",
      "In epoch 25, loss: 0.4712483882904053\n",
      "In epoch 30, loss: 0.4452245235443115\n",
      "In epoch 35, loss: 0.4097415506839752\n",
      "In epoch 40, loss: 0.3833618760108948\n",
      "In epoch 45, loss: 0.35520023107528687\n",
      "In epoch 50, loss: 0.32729968428611755\n",
      "In epoch 55, loss: 0.29808664321899414\n",
      "In epoch 60, loss: 0.2682197690010071\n",
      "In epoch 65, loss: 0.23794840276241302\n",
      "In epoch 70, loss: 0.2076166570186615\n",
      "In epoch 75, loss: 0.17821840941905975\n",
      "In epoch 80, loss: 0.1500256508588791\n",
      "In epoch 85, loss: 0.1233985647559166\n",
      "In epoch 90, loss: 0.09837648272514343\n",
      "In epoch 95, loss: 0.07606442272663116\n",
      "In epoch 100, loss: 0.056776903569698334\n",
      "AUC 0.8300667100918667\n",
      "In epoch 105, loss: 0.04092235863208771\n",
      "In epoch 110, loss: 0.028636062517762184\n",
      "In epoch 115, loss: 0.019585611298680305\n",
      "In epoch 120, loss: 0.013291393406689167\n",
      "In epoch 125, loss: 0.009067066013813019\n",
      "In epoch 130, loss: 0.006315000355243683\n",
      "In epoch 135, loss: 0.0045520225539803505\n",
      "In epoch 140, loss: 0.0034147908445447683\n",
      "In epoch 145, loss: 0.0026642221491783857\n",
      "In epoch 150, loss: 0.0021533190738409758\n",
      "In epoch 155, loss: 0.0017931879265233874\n",
      "In epoch 160, loss: 0.0015285364352166653\n",
      "In epoch 165, loss: 0.0013276970712468028\n",
      "In epoch 170, loss: 0.0011700608301907778\n",
      "In epoch 175, loss: 0.0010425690561532974\n",
      "In epoch 180, loss: 0.0009370645857416093\n",
      "In epoch 185, loss: 0.0008482445846311748\n",
      "In epoch 190, loss: 0.0007724138558842242\n",
      "In epoch 195, loss: 0.0007070923456922174\n",
      "In epoch 200, loss: 0.0006503943004645407\n",
      "AUC 0.8316686507490846\n",
      "In epoch 205, loss: 0.000600760686211288\n",
      "In epoch 210, loss: 0.0005570851499214768\n",
      "In epoch 215, loss: 0.0005184468463994563\n",
      "In epoch 220, loss: 0.0004841031040996313\n",
      "In epoch 225, loss: 0.00045339696225710213\n",
      "In epoch 230, loss: 0.00042580152512528\n",
      "In epoch 235, loss: 0.0004009163531009108\n",
      "In epoch 240, loss: 0.00037833122769370675\n",
      "In epoch 245, loss: 0.00035776503500528634\n",
      "In epoch 250, loss: 0.00033896914101205766\n",
      "In epoch 255, loss: 0.0003217291086912155\n",
      "In epoch 260, loss: 0.0003058813454117626\n",
      "In epoch 265, loss: 0.0002912607160396874\n",
      "In epoch 270, loss: 0.00027774606132879853\n",
      "In epoch 275, loss: 0.00026521761901676655\n",
      "In epoch 280, loss: 0.0002535800158511847\n",
      "In epoch 285, loss: 0.0002427410363452509\n",
      "In epoch 290, loss: 0.00023262864851858467\n",
      "In epoch 295, loss: 0.00022316985996440053\n",
      "In epoch 300, loss: 0.0002143067104043439\n",
      "AUC 0.8321457289818288\n",
      "In epoch 305, loss: 0.000205983393243514\n",
      "In epoch 310, loss: 0.0001981605018954724\n",
      "In epoch 315, loss: 0.000190800114069134\n",
      "In epoch 320, loss: 0.0001838624302763492\n",
      "In epoch 325, loss: 0.00017731521802488714\n",
      "In epoch 330, loss: 0.00017112534260377288\n",
      "In epoch 335, loss: 0.00016526701801922172\n",
      "In epoch 340, loss: 0.00015971502580214292\n",
      "In epoch 345, loss: 0.0001544522529002279\n",
      "In epoch 350, loss: 0.00014945799193810672\n",
      "In epoch 355, loss: 0.00014471237955149263\n",
      "In epoch 360, loss: 0.0001401979970978573\n",
      "In epoch 365, loss: 0.00013590189337264746\n",
      "In epoch 370, loss: 0.0001318084105150774\n",
      "In epoch 375, loss: 0.0001279021380469203\n",
      "In epoch 380, loss: 0.0001241742429556325\n",
      "In epoch 385, loss: 0.00012061309826094657\n",
      "In epoch 390, loss: 0.00011720851762220263\n",
      "In epoch 395, loss: 0.00011395005276426673\n",
      "In epoch 400, loss: 0.00011082996934419498\n",
      "AUC 0.8324790548280587\n",
      "In epoch 405, loss: 0.00010784083133330569\n",
      "In epoch 410, loss: 0.00010497411858523265\n",
      "In epoch 415, loss: 0.00010222335549769923\n",
      "In epoch 420, loss: 9.958182636182755e-05\n",
      "In epoch 425, loss: 9.704461990622804e-05\n",
      "In epoch 430, loss: 9.460655564907938e-05\n",
      "In epoch 435, loss: 9.226154361385852e-05\n",
      "In epoch 440, loss: 9.000531281344593e-05\n",
      "In epoch 445, loss: 8.78324790392071e-05\n",
      "In epoch 450, loss: 8.57408667798154e-05\n",
      "In epoch 455, loss: 8.372461888939142e-05\n",
      "In epoch 460, loss: 8.178053394658491e-05\n",
      "In epoch 465, loss: 7.990583981154487e-05\n",
      "In epoch 470, loss: 7.809553790139034e-05\n",
      "In epoch 475, loss: 7.634672510903329e-05\n",
      "In epoch 480, loss: 7.465713861165568e-05\n",
      "In epoch 485, loss: 7.302274752873927e-05\n",
      "In epoch 490, loss: 7.144307892303914e-05\n",
      "In epoch 495, loss: 6.99144511600025e-05\n",
      "In epoch 500, loss: 6.843471783213317e-05\n",
      "AUC 0.8327948608521821\n",
      "In epoch 505, loss: 6.7002561991103e-05\n",
      "In epoch 510, loss: 6.56142583466135e-05\n",
      "In epoch 515, loss: 6.426949403248727e-05\n",
      "In epoch 520, loss: 6.29666174063459e-05\n",
      "In epoch 525, loss: 6.170328560983762e-05\n",
      "In epoch 530, loss: 6.047756687621586e-05\n",
      "In epoch 535, loss: 5.928758764639497e-05\n",
      "In epoch 540, loss: 5.8132533013122156e-05\n",
      "In epoch 545, loss: 5.701142436009832e-05\n",
      "In epoch 550, loss: 5.59231084480416e-05\n",
      "In epoch 555, loss: 5.486577720148489e-05\n",
      "In epoch 560, loss: 5.383825191529468e-05\n",
      "In epoch 565, loss: 5.2839626732748e-05\n",
      "In epoch 570, loss: 5.186943963053636e-05\n",
      "In epoch 575, loss: 5.092587889521383e-05\n",
      "In epoch 580, loss: 5.00086389365606e-05\n",
      "In epoch 585, loss: 4.911584619549103e-05\n",
      "In epoch 590, loss: 4.8247238737531006e-05\n",
      "In epoch 595, loss: 4.7402056225109845e-05\n",
      "In epoch 600, loss: 4.657909812522121e-05\n",
      "AUC 0.8331744569978212\n",
      "In epoch 605, loss: 4.5777549530612305e-05\n",
      "In epoch 610, loss: 4.4996610085945576e-05\n",
      "In epoch 615, loss: 4.423546852194704e-05\n",
      "In epoch 620, loss: 4.3494303099578246e-05\n",
      "In epoch 625, loss: 4.277141852071509e-05\n",
      "In epoch 630, loss: 4.206675657769665e-05\n",
      "In epoch 635, loss: 4.137967334827408e-05\n",
      "In epoch 640, loss: 4.070952854817733e-05\n",
      "In epoch 645, loss: 4.005515074823052e-05\n",
      "In epoch 650, loss: 3.9417169318767264e-05\n",
      "In epoch 655, loss: 3.879471114487387e-05\n",
      "In epoch 660, loss: 3.818632467300631e-05\n",
      "In epoch 665, loss: 3.759246465051547e-05\n",
      "In epoch 670, loss: 3.701215609908104e-05\n",
      "In epoch 675, loss: 3.644546814030036e-05\n",
      "In epoch 680, loss: 3.589141124393791e-05\n",
      "In epoch 685, loss: 3.534990901243873e-05\n",
      "In epoch 690, loss: 3.4820695873349905e-05\n",
      "In epoch 695, loss: 3.4303258871659636e-05\n",
      "In epoch 700, loss: 3.379699046490714e-05\n",
      "AUC 0.8333415691471442\n",
      "In epoch 705, loss: 3.3301839721389115e-05\n",
      "In epoch 710, loss: 3.281714452896267e-05\n",
      "In epoch 715, loss: 3.2343348721042275e-05\n",
      "In epoch 720, loss: 3.187944457749836e-05\n",
      "In epoch 725, loss: 3.142524292343296e-05\n",
      "In epoch 730, loss: 3.098131128353998e-05\n",
      "In epoch 735, loss: 3.054657281609252e-05\n",
      "In epoch 740, loss: 3.0120578230707906e-05\n",
      "In epoch 745, loss: 2.970384775835555e-05\n",
      "In epoch 750, loss: 2.9295448257471435e-05\n",
      "In epoch 755, loss: 2.889591814891901e-05\n",
      "In epoch 760, loss: 2.8503793146228418e-05\n",
      "In epoch 765, loss: 2.811980630212929e-05\n",
      "In epoch 770, loss: 2.7743952159653418e-05\n",
      "In epoch 775, loss: 2.7375248464522883e-05\n",
      "In epoch 780, loss: 2.7013507860829122e-05\n",
      "In epoch 785, loss: 2.6659310606191866e-05\n",
      "In epoch 790, loss: 2.6312020054319873e-05\n",
      "In epoch 795, loss: 2.597119237179868e-05\n",
      "In epoch 800, loss: 2.563723683124408e-05\n",
      "AUC 0.833530244154444\n",
      "In epoch 805, loss: 2.530883466533851e-05\n",
      "In epoch 810, loss: 2.498680078133475e-05\n",
      "In epoch 815, loss: 2.4671238861628808e-05\n",
      "In epoch 820, loss: 2.4361093892366625e-05\n",
      "In epoch 825, loss: 2.40570825553732e-05\n",
      "In epoch 830, loss: 2.3758495444781147e-05\n",
      "In epoch 835, loss: 2.346544169995468e-05\n",
      "In epoch 840, loss: 2.3178132323664613e-05\n",
      "In epoch 845, loss: 2.2895526853972115e-05\n",
      "In epoch 850, loss: 2.2618070943281054e-05\n",
      "In epoch 855, loss: 2.234553721791599e-05\n",
      "In epoch 860, loss: 2.2077883841120638e-05\n",
      "In epoch 865, loss: 2.181509080401156e-05\n",
      "In epoch 870, loss: 2.1556792489718646e-05\n",
      "In epoch 875, loss: 2.130333086824976e-05\n",
      "In epoch 880, loss: 2.1054083845228888e-05\n",
      "In epoch 885, loss: 2.0809426132473163e-05\n",
      "In epoch 890, loss: 2.056853372778278e-05\n",
      "In epoch 895, loss: 2.033188138739206e-05\n",
      "In epoch 900, loss: 2.009943636949174e-05\n",
      "AUC 0.8337827092832595\n",
      "In epoch 905, loss: 1.986994539038278e-05\n",
      "In epoch 910, loss: 1.96449054783443e-05\n",
      "In epoch 915, loss: 1.9423567209742032e-05\n",
      "In epoch 920, loss: 1.920584873005282e-05\n",
      "In epoch 925, loss: 1.8991860997630283e-05\n",
      "In epoch 930, loss: 1.8781047401716933e-05\n",
      "In epoch 935, loss: 1.857400275184773e-05\n",
      "In epoch 940, loss: 1.837015588534996e-05\n",
      "In epoch 945, loss: 1.8169333998230286e-05\n",
      "In epoch 950, loss: 1.7972166460822336e-05\n",
      "In epoch 955, loss: 1.7777967514120974e-05\n",
      "In epoch 960, loss: 1.758686630637385e-05\n",
      "In epoch 965, loss: 1.739879371598363e-05\n",
      "In epoch 970, loss: 1.7213556930073537e-05\n",
      "In epoch 975, loss: 1.7031543393386528e-05\n",
      "In epoch 980, loss: 1.685169445408974e-05\n",
      "In epoch 985, loss: 1.667511969571933e-05\n",
      "In epoch 990, loss: 1.650137892283965e-05\n",
      "In epoch 995, loss: 1.633003557799384e-05\n",
      "In epoch 1000, loss: 1.616120971448254e-05\n",
      "AUC 0.833931852384268\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### GCN Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='gcn')\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.686556875705719\n",
      "In epoch 10, loss: 0.643485963344574\n",
      "In epoch 15, loss: 0.5428742170333862\n",
      "In epoch 20, loss: 0.4904618263244629\n",
      "In epoch 25, loss: 0.44681820273399353\n",
      "In epoch 30, loss: 0.4194025993347168\n",
      "In epoch 35, loss: 0.38941270112991333\n",
      "In epoch 40, loss: 0.35995498299598694\n",
      "In epoch 45, loss: 0.33258068561553955\n",
      "In epoch 50, loss: 0.3026009202003479\n",
      "In epoch 55, loss: 0.271589070558548\n",
      "In epoch 60, loss: 0.2396003156900406\n",
      "In epoch 65, loss: 0.2069946527481079\n",
      "In epoch 70, loss: 0.17451974749565125\n",
      "In epoch 75, loss: 0.14302337169647217\n",
      "In epoch 80, loss: 0.1133245974779129\n",
      "In epoch 85, loss: 0.0862024575471878\n",
      "In epoch 90, loss: 0.06280785799026489\n",
      "In epoch 95, loss: 0.04354257509112358\n",
      "In epoch 100, loss: 0.028820054605603218\n",
      "AUC 0.8438301026481885\n",
      "In epoch 105, loss: 0.018501784652471542\n",
      "In epoch 110, loss: 0.011833741329610348\n",
      "In epoch 115, loss: 0.0077272020280361176\n",
      "In epoch 120, loss: 0.00523754907771945\n",
      "In epoch 125, loss: 0.0037135283928364515\n",
      "In epoch 130, loss: 0.0027576659340411425\n",
      "In epoch 135, loss: 0.0021388200111687183\n",
      "In epoch 140, loss: 0.001721144188195467\n",
      "In epoch 145, loss: 0.0014284581411629915\n",
      "In epoch 150, loss: 0.0012159185716882348\n",
      "In epoch 155, loss: 0.0010557558853179216\n",
      "In epoch 160, loss: 0.0009309172164648771\n",
      "In epoch 165, loss: 0.0008306482341140509\n",
      "In epoch 170, loss: 0.0007480488275177777\n",
      "In epoch 175, loss: 0.0006786230951547623\n",
      "In epoch 180, loss: 0.0006194990710355341\n",
      "In epoch 185, loss: 0.0005686667282134295\n",
      "In epoch 190, loss: 0.000524544739164412\n",
      "In epoch 195, loss: 0.00048590099322609603\n",
      "In epoch 200, loss: 0.00045182520989328623\n",
      "AUC 0.8397780822533185\n",
      "In epoch 205, loss: 0.0004216075176373124\n",
      "In epoch 210, loss: 0.0003946599899791181\n",
      "In epoch 215, loss: 0.00037048940430395305\n",
      "In epoch 220, loss: 0.00034870649687945843\n",
      "In epoch 225, loss: 0.0003289755550213158\n",
      "In epoch 230, loss: 0.0003110366524197161\n",
      "In epoch 235, loss: 0.00029466336127370596\n",
      "In epoch 240, loss: 0.00027966199559159577\n",
      "In epoch 245, loss: 0.00026587810134515166\n",
      "In epoch 250, loss: 0.00025316872051917017\n",
      "In epoch 255, loss: 0.00024142404436133802\n",
      "In epoch 260, loss: 0.00023053861514199525\n",
      "In epoch 265, loss: 0.00022042238560970873\n",
      "In epoch 270, loss: 0.00021100588492117822\n",
      "In epoch 275, loss: 0.0002022156841121614\n",
      "In epoch 280, loss: 0.0001940005022333935\n",
      "In epoch 285, loss: 0.00018630696285981685\n",
      "In epoch 290, loss: 0.00017909074085764587\n",
      "In epoch 295, loss: 0.00017230973753612489\n",
      "In epoch 300, loss: 0.00016592924657743424\n",
      "AUC 0.8396783540351744\n",
      "In epoch 305, loss: 0.00015991638065315783\n",
      "In epoch 310, loss: 0.0001542410027468577\n",
      "In epoch 315, loss: 0.00014887863653711975\n",
      "In epoch 320, loss: 0.00014380474749486893\n",
      "In epoch 325, loss: 0.0001389983663102612\n",
      "In epoch 330, loss: 0.00013444005162455142\n",
      "In epoch 335, loss: 0.0001301127631450072\n",
      "In epoch 340, loss: 0.00012600026093423367\n",
      "In epoch 345, loss: 0.00012208901171106845\n",
      "In epoch 350, loss: 0.00011836365592898801\n",
      "In epoch 355, loss: 0.00011481512046884745\n",
      "In epoch 360, loss: 0.000111429973912891\n",
      "In epoch 365, loss: 0.00010819989256560802\n",
      "In epoch 370, loss: 0.00010511284926906228\n",
      "In epoch 375, loss: 0.0001021607022266835\n",
      "In epoch 380, loss: 9.93353096419014e-05\n",
      "In epoch 385, loss: 9.662889351602644e-05\n",
      "In epoch 390, loss: 9.403548028785735e-05\n",
      "In epoch 395, loss: 9.154869621852413e-05\n",
      "In epoch 400, loss: 8.916224032873288e-05\n",
      "AUC 0.8397178859414659\n",
      "In epoch 405, loss: 8.68714414536953e-05\n",
      "In epoch 410, loss: 8.467058069072664e-05\n",
      "In epoch 415, loss: 8.255404827650636e-05\n",
      "In epoch 420, loss: 8.051929762586951e-05\n",
      "In epoch 425, loss: 7.856097363401204e-05\n",
      "In epoch 430, loss: 7.66763769206591e-05\n",
      "In epoch 435, loss: 7.485845708288252e-05\n",
      "In epoch 440, loss: 7.310532237170264e-05\n",
      "In epoch 445, loss: 7.141484093153849e-05\n",
      "In epoch 450, loss: 6.9782356149517e-05\n",
      "In epoch 455, loss: 6.820700946263969e-05\n",
      "In epoch 460, loss: 6.668521382380277e-05\n",
      "In epoch 465, loss: 6.521615432575345e-05\n",
      "In epoch 470, loss: 6.379564729286358e-05\n",
      "In epoch 475, loss: 6.242252857191488e-05\n",
      "In epoch 480, loss: 6.109444075264037e-05\n",
      "In epoch 485, loss: 5.980896094115451e-05\n",
      "In epoch 490, loss: 5.856445204699412e-05\n",
      "In epoch 495, loss: 5.735958620789461e-05\n",
      "In epoch 500, loss: 5.619169678539038e-05\n",
      "AUC 0.8399604680937085\n",
      "In epoch 505, loss: 5.506047455128282e-05\n",
      "In epoch 510, loss: 5.3962932724971324e-05\n",
      "In epoch 515, loss: 5.28990822203923e-05\n",
      "In epoch 520, loss: 5.186700218473561e-05\n",
      "In epoch 525, loss: 5.086501550977118e-05\n",
      "In epoch 530, loss: 4.989195804228075e-05\n",
      "In epoch 535, loss: 4.894704761682078e-05\n",
      "In epoch 540, loss: 4.802902913070284e-05\n",
      "In epoch 545, loss: 4.713699308922514e-05\n",
      "In epoch 550, loss: 4.626957525033504e-05\n",
      "In epoch 555, loss: 4.542659371509217e-05\n",
      "In epoch 560, loss: 4.4606495066545904e-05\n",
      "In epoch 565, loss: 4.380882455734536e-05\n",
      "In epoch 570, loss: 4.30324325861875e-05\n",
      "In epoch 575, loss: 4.2277304601157084e-05\n",
      "In epoch 580, loss: 4.1541898099239916e-05\n",
      "In epoch 585, loss: 4.0825947507983074e-05\n",
      "In epoch 590, loss: 4.0128030377672985e-05\n",
      "In epoch 595, loss: 3.9448641473427415e-05\n",
      "In epoch 600, loss: 3.878572897519916e-05\n",
      "AUC 0.8400817591698299\n",
      "In epoch 605, loss: 3.814026422332972e-05\n",
      "In epoch 610, loss: 3.7510682886932045e-05\n",
      "In epoch 615, loss: 3.689677396323532e-05\n",
      "In epoch 620, loss: 3.6297646147431806e-05\n",
      "In epoch 625, loss: 3.571366687538102e-05\n",
      "In epoch 630, loss: 3.5143704735673964e-05\n",
      "In epoch 635, loss: 3.4587479603942484e-05\n",
      "In epoch 640, loss: 3.4044100175378844e-05\n",
      "In epoch 645, loss: 3.3513493690406904e-05\n",
      "In epoch 650, loss: 3.299550007795915e-05\n",
      "In epoch 655, loss: 3.248928260290995e-05\n",
      "In epoch 660, loss: 3.199397542630322e-05\n",
      "In epoch 665, loss: 3.151063356199302e-05\n",
      "In epoch 670, loss: 3.103791459579952e-05\n",
      "In epoch 675, loss: 3.057563299080357e-05\n",
      "In epoch 680, loss: 3.0123834221740253e-05\n",
      "In epoch 685, loss: 2.968215267173946e-05\n",
      "In epoch 690, loss: 2.9250093575683422e-05\n",
      "In epoch 695, loss: 2.88273276964901e-05\n",
      "In epoch 700, loss: 2.8413840482244268e-05\n",
      "AUC 0.8401581276251656\n",
      "In epoch 705, loss: 2.8009160814690404e-05\n",
      "In epoch 710, loss: 2.7613117708824575e-05\n",
      "In epoch 715, loss: 2.7225511075812392e-05\n",
      "In epoch 720, loss: 2.684579521883279e-05\n",
      "In epoch 725, loss: 2.647408291522879e-05\n",
      "In epoch 730, loss: 2.611017771414481e-05\n",
      "In epoch 735, loss: 2.5753488444024697e-05\n",
      "In epoch 740, loss: 2.540441528253723e-05\n",
      "In epoch 745, loss: 2.5062367058126256e-05\n",
      "In epoch 750, loss: 2.4727009076741524e-05\n",
      "In epoch 755, loss: 2.4397930246777833e-05\n",
      "In epoch 760, loss: 2.4075978217297234e-05\n",
      "In epoch 765, loss: 2.3760068870615214e-05\n",
      "In epoch 770, loss: 2.3450365915778093e-05\n",
      "In epoch 775, loss: 2.314700759598054e-05\n",
      "In epoch 780, loss: 2.2848738808534108e-05\n",
      "In epoch 785, loss: 2.2556634576176293e-05\n",
      "In epoch 790, loss: 2.2269849068834446e-05\n",
      "In epoch 795, loss: 2.1988416847307235e-05\n",
      "In epoch 800, loss: 2.1712334273615852e-05\n",
      "AUC 0.8401832842928056\n",
      "In epoch 805, loss: 2.1441650460474193e-05\n",
      "In epoch 810, loss: 2.1175850633881055e-05\n",
      "In epoch 815, loss: 2.0914952983730473e-05\n",
      "In epoch 820, loss: 2.0658761059166864e-05\n",
      "In epoch 825, loss: 2.04072093765717e-05\n",
      "In epoch 830, loss: 2.015991776715964e-05\n",
      "In epoch 835, loss: 1.991722092498094e-05\n",
      "In epoch 840, loss: 1.967905518540647e-05\n",
      "In epoch 845, loss: 1.9444856661721133e-05\n",
      "In epoch 850, loss: 1.9214792700950056e-05\n",
      "In epoch 855, loss: 1.898921254905872e-05\n",
      "In epoch 860, loss: 1.8766850189422257e-05\n",
      "In epoch 865, loss: 1.8548731532064267e-05\n",
      "In epoch 870, loss: 1.8333885236643255e-05\n",
      "In epoch 875, loss: 1.8123482732335106e-05\n",
      "In epoch 880, loss: 1.7915910575538874e-05\n",
      "In epoch 885, loss: 1.771223105606623e-05\n",
      "In epoch 890, loss: 1.7511663827463053e-05\n",
      "In epoch 895, loss: 1.731460179144051e-05\n",
      "In epoch 900, loss: 1.712098492134828e-05\n",
      "AUC 0.840235394532917\n",
      "In epoch 905, loss: 1.6929898265516385e-05\n",
      "In epoch 910, loss: 1.6742516891099513e-05\n",
      "In epoch 915, loss: 1.655785490584094e-05\n",
      "In epoch 920, loss: 1.6376268831663765e-05\n",
      "In epoch 925, loss: 1.6198066077777185e-05\n",
      "In epoch 930, loss: 1.6022235286072828e-05\n",
      "In epoch 935, loss: 1.5848554539843462e-05\n",
      "In epoch 940, loss: 1.5678382624173537e-05\n",
      "In epoch 945, loss: 1.5510562661802396e-05\n",
      "In epoch 950, loss: 1.534546936454717e-05\n",
      "In epoch 955, loss: 1.5182890820142347e-05\n",
      "In epoch 960, loss: 1.5022727893665433e-05\n",
      "In epoch 965, loss: 1.4865256162011065e-05\n",
      "In epoch 970, loss: 1.4710048162669409e-05\n",
      "In epoch 975, loss: 1.4557206668541767e-05\n",
      "In epoch 980, loss: 1.4406463378691114e-05\n",
      "In epoch 985, loss: 1.4258394003263675e-05\n",
      "In epoch 990, loss: 1.4112910321273375e-05\n",
      "In epoch 995, loss: 1.396882908011321e-05\n",
      "In epoch 1000, loss: 1.3827162547386251e-05\n",
      "AUC 0.8402488713191527\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphEVE(train_g.ndata[\"x\"].shape[1], 32)\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 1.7157373428344727\n",
      "In epoch 10, loss: 1.2917133569717407\n",
      "In epoch 15, loss: 0.9996211528778076\n",
      "In epoch 20, loss: 0.8414434194564819\n",
      "In epoch 25, loss: 0.7633099555969238\n",
      "In epoch 30, loss: 0.728997528553009\n",
      "In epoch 35, loss: 0.7129287719726562\n",
      "In epoch 40, loss: 0.7048670649528503\n",
      "In epoch 45, loss: 0.7007914781570435\n",
      "In epoch 50, loss: 0.6985613703727722\n",
      "In epoch 55, loss: 0.6971836090087891\n",
      "In epoch 60, loss: 0.6962661147117615\n",
      "In epoch 65, loss: 0.6956084370613098\n",
      "In epoch 70, loss: 0.6950979232788086\n",
      "In epoch 75, loss: 0.694654107093811\n",
      "In epoch 80, loss: 0.6942159533500671\n",
      "In epoch 85, loss: 0.693648636341095\n",
      "In epoch 90, loss: 0.6929836869239807\n",
      "In epoch 95, loss: 0.692043125629425\n",
      "In epoch 100, loss: 0.6906965970993042\n",
      "AUC 0.6410053682531839\n",
      "In epoch 105, loss: 0.6887556314468384\n",
      "In epoch 110, loss: 0.6859110593795776\n",
      "In epoch 115, loss: 0.6817203164100647\n",
      "In epoch 120, loss: 0.6753854155540466\n",
      "In epoch 125, loss: 0.6656451225280762\n",
      "In epoch 130, loss: 0.6513359546661377\n",
      "In epoch 135, loss: 0.6331420540809631\n",
      "In epoch 140, loss: 0.6142939925193787\n",
      "In epoch 145, loss: 0.5979014039039612\n",
      "In epoch 150, loss: 0.5852171778678894\n",
      "In epoch 155, loss: 0.5742214322090149\n",
      "In epoch 160, loss: 0.5644283294677734\n",
      "In epoch 165, loss: 0.5555824637413025\n",
      "In epoch 170, loss: 0.5474531650543213\n",
      "In epoch 175, loss: 0.5401026606559753\n",
      "In epoch 180, loss: 0.533164918422699\n",
      "In epoch 185, loss: 0.5264574885368347\n",
      "In epoch 190, loss: 0.5206353664398193\n",
      "In epoch 195, loss: 0.5136266350746155\n",
      "In epoch 200, loss: 0.5065412521362305\n",
      "AUC 0.7368980930347477\n",
      "In epoch 205, loss: 0.4988440275192261\n",
      "In epoch 210, loss: 0.49005746841430664\n",
      "In epoch 215, loss: 0.48059290647506714\n",
      "In epoch 220, loss: 0.47160348296165466\n",
      "In epoch 225, loss: 0.46389535069465637\n",
      "In epoch 230, loss: 0.45767638087272644\n",
      "In epoch 235, loss: 0.45191559195518494\n",
      "In epoch 240, loss: 0.44588157534599304\n",
      "In epoch 245, loss: 0.44024139642715454\n",
      "In epoch 250, loss: 0.4348418116569519\n",
      "In epoch 255, loss: 0.4294985830783844\n",
      "In epoch 260, loss: 0.424377977848053\n",
      "In epoch 265, loss: 0.41945868730545044\n",
      "In epoch 270, loss: 0.41439494490623474\n",
      "In epoch 275, loss: 0.4091222584247589\n",
      "In epoch 280, loss: 0.4046178162097931\n",
      "In epoch 285, loss: 0.39934495091438293\n",
      "In epoch 290, loss: 0.39489901065826416\n",
      "In epoch 295, loss: 0.389651894569397\n",
      "In epoch 300, loss: 0.38607606291770935\n",
      "AUC 0.7846589250016845\n",
      "In epoch 305, loss: 0.3804578185081482\n",
      "In epoch 310, loss: 0.37592801451683044\n",
      "In epoch 315, loss: 0.37162014842033386\n",
      "In epoch 320, loss: 0.3670538663864136\n",
      "In epoch 325, loss: 0.3624585270881653\n",
      "In epoch 330, loss: 0.35777029395103455\n",
      "In epoch 335, loss: 0.35316962003707886\n",
      "In epoch 340, loss: 0.34834912419319153\n",
      "In epoch 345, loss: 0.34389305114746094\n",
      "In epoch 350, loss: 0.3387482464313507\n",
      "In epoch 355, loss: 0.33331969380378723\n",
      "In epoch 360, loss: 0.32745376229286194\n",
      "In epoch 365, loss: 0.32106050848960876\n",
      "In epoch 370, loss: 0.3164026141166687\n",
      "In epoch 375, loss: 0.3087847828865051\n",
      "In epoch 380, loss: 0.30226650834083557\n",
      "In epoch 385, loss: 0.29556921124458313\n",
      "In epoch 390, loss: 0.2886021137237549\n",
      "In epoch 395, loss: 0.28167474269866943\n",
      "In epoch 400, loss: 0.27493709325790405\n",
      "AUC 0.7905482805866894\n",
      "In epoch 405, loss: 0.26682227849960327\n",
      "In epoch 410, loss: 0.2605298161506653\n",
      "In epoch 415, loss: 0.2517302930355072\n",
      "In epoch 420, loss: 0.24467572569847107\n",
      "In epoch 425, loss: 0.23693162202835083\n",
      "In epoch 430, loss: 0.2302454262971878\n",
      "In epoch 435, loss: 0.2219591587781906\n",
      "In epoch 440, loss: 0.21637974679470062\n",
      "In epoch 445, loss: 0.20753027498722076\n",
      "In epoch 450, loss: 0.20101192593574524\n",
      "In epoch 455, loss: 0.1939965933561325\n",
      "In epoch 460, loss: 0.18718796968460083\n",
      "In epoch 465, loss: 0.1828339695930481\n",
      "In epoch 470, loss: 0.1746615767478943\n",
      "In epoch 475, loss: 0.16873109340667725\n",
      "In epoch 480, loss: 0.16172809898853302\n",
      "In epoch 485, loss: 0.1566026359796524\n",
      "In epoch 490, loss: 0.14892905950546265\n",
      "In epoch 495, loss: 0.14376680552959442\n",
      "In epoch 500, loss: 0.1365734189748764\n",
      "AUC 0.7798872442218279\n",
      "In epoch 505, loss: 0.13164032995700836\n",
      "In epoch 510, loss: 0.12700429558753967\n",
      "In epoch 515, loss: 0.1221560463309288\n",
      "In epoch 520, loss: 0.11336969584226608\n",
      "In epoch 525, loss: 0.10735923796892166\n",
      "In epoch 530, loss: 0.10204995423555374\n",
      "In epoch 535, loss: 0.09678167849779129\n",
      "In epoch 540, loss: 0.09071151912212372\n",
      "In epoch 545, loss: 0.08574807643890381\n",
      "In epoch 550, loss: 0.07973281294107437\n",
      "In epoch 555, loss: 0.07469083368778229\n",
      "In epoch 560, loss: 0.06943878531455994\n",
      "In epoch 565, loss: 0.06456729024648666\n",
      "In epoch 570, loss: 0.05987958610057831\n",
      "In epoch 575, loss: 0.055518172681331635\n",
      "In epoch 580, loss: 0.05147327855229378\n",
      "In epoch 585, loss: 0.04755891487002373\n",
      "In epoch 590, loss: 0.04402007907629013\n",
      "In epoch 595, loss: 0.040864247828722\n",
      "In epoch 600, loss: 0.037801723927259445\n",
      "AUC 0.7761919094359965\n",
      "In epoch 605, loss: 0.034933559596538544\n",
      "In epoch 610, loss: 0.03229351341724396\n",
      "In epoch 615, loss: 0.029882265254855156\n",
      "In epoch 620, loss: 0.02771804854273796\n",
      "In epoch 625, loss: 0.025686128064990044\n",
      "In epoch 630, loss: 0.02385011874139309\n",
      "In epoch 635, loss: 0.02214922569692135\n",
      "In epoch 640, loss: 0.020635122433304787\n",
      "In epoch 645, loss: 0.019252773374319077\n",
      "In epoch 650, loss: 0.017987804487347603\n",
      "In epoch 655, loss: 0.016819018870592117\n",
      "In epoch 660, loss: 0.015742719173431396\n",
      "In epoch 665, loss: 0.014746718108654022\n",
      "In epoch 670, loss: 0.013837742619216442\n",
      "In epoch 675, loss: 0.013005985878407955\n",
      "In epoch 680, loss: 0.01222532894462347\n",
      "In epoch 685, loss: 0.011519352905452251\n",
      "In epoch 690, loss: 0.010871157050132751\n",
      "In epoch 695, loss: 0.010279925540089607\n",
      "In epoch 700, loss: 0.009742533788084984\n",
      "AUC 0.7778468587857414\n",
      "In epoch 705, loss: 0.009251974523067474\n",
      "In epoch 710, loss: 0.008800297975540161\n",
      "In epoch 715, loss: 0.008382917381823063\n",
      "In epoch 720, loss: 0.008001187816262245\n",
      "In epoch 725, loss: 0.007648385129868984\n",
      "In epoch 730, loss: 0.007321608252823353\n",
      "In epoch 735, loss: 0.007021417375653982\n",
      "In epoch 740, loss: 0.0067361826077103615\n",
      "In epoch 745, loss: 0.006477954797446728\n",
      "In epoch 750, loss: 0.006228735204786062\n",
      "In epoch 755, loss: 0.006002137903124094\n",
      "In epoch 760, loss: 0.00578637421131134\n",
      "In epoch 765, loss: 0.005584435071796179\n",
      "In epoch 770, loss: 0.005402362439781427\n",
      "In epoch 775, loss: 0.0052276854403316975\n",
      "In epoch 780, loss: 0.005067573394626379\n",
      "In epoch 785, loss: 0.004916760139167309\n",
      "In epoch 790, loss: 0.004768922924995422\n",
      "In epoch 795, loss: 0.004629591945558786\n",
      "In epoch 800, loss: 0.004499826580286026\n",
      "AUC 0.7764767188517777\n",
      "In epoch 805, loss: 0.004376101307570934\n",
      "In epoch 810, loss: 0.0042587281204760075\n",
      "In epoch 815, loss: 0.004146246705204248\n",
      "In epoch 820, loss: 0.004041479900479317\n",
      "In epoch 825, loss: 0.0039453571662306786\n",
      "In epoch 830, loss: 0.003851762507110834\n",
      "In epoch 835, loss: 0.0037605667021125555\n",
      "In epoch 840, loss: 0.0036741485819220543\n",
      "In epoch 845, loss: 0.0035954881459474564\n",
      "In epoch 850, loss: 0.0035172407515347004\n",
      "In epoch 855, loss: 0.0034456558059901\n",
      "In epoch 860, loss: 0.0033742685336619616\n",
      "In epoch 865, loss: 0.003307025646790862\n",
      "In epoch 870, loss: 0.0032454580068588257\n",
      "In epoch 875, loss: 0.003182582091540098\n",
      "In epoch 880, loss: 0.0031239157542586327\n",
      "In epoch 885, loss: 0.0030684038065373898\n",
      "In epoch 890, loss: 0.00301126460544765\n",
      "In epoch 895, loss: 0.0029557165689766407\n",
      "In epoch 900, loss: 0.002904796740040183\n",
      "AUC 0.775198221064217\n",
      "In epoch 905, loss: 0.002853090176358819\n",
      "In epoch 910, loss: 0.0028049631509929895\n",
      "In epoch 915, loss: 0.0027570025995373726\n",
      "In epoch 920, loss: 0.0027132672257721424\n",
      "In epoch 925, loss: 0.0026689490769058466\n",
      "In epoch 930, loss: 0.0026274840347468853\n",
      "In epoch 935, loss: 0.0025862904731184244\n",
      "In epoch 940, loss: 0.0025484496727585793\n",
      "In epoch 945, loss: 0.0025105164386332035\n",
      "In epoch 950, loss: 0.002474011154845357\n",
      "In epoch 955, loss: 0.0024398337118327618\n",
      "In epoch 960, loss: 0.002405789913609624\n",
      "In epoch 965, loss: 0.0023673141840845346\n",
      "In epoch 970, loss: 0.002331014256924391\n",
      "In epoch 975, loss: 0.0022963709197938442\n",
      "In epoch 980, loss: 0.0022630293387919664\n",
      "In epoch 985, loss: 0.0022328905761241913\n",
      "In epoch 990, loss: 0.0022020875476300716\n",
      "In epoch 995, loss: 0.0021748121362179518\n",
      "In epoch 1000, loss: 0.002146389801055193\n",
      "AUC 0.7750050537948384\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actor model\n",
    "actor = Actor(root='data/Actor', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(actor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 16, agg='mean')\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6794610023498535\n",
      "In epoch 10, loss: 0.6584976315498352\n",
      "In epoch 15, loss: 0.6445634961128235\n",
      "In epoch 20, loss: 0.6313113570213318\n",
      "In epoch 25, loss: 0.6205123662948608\n",
      "In epoch 30, loss: 0.6073060631752014\n",
      "In epoch 35, loss: 0.5939508080482483\n",
      "In epoch 40, loss: 0.5797938108444214\n",
      "In epoch 45, loss: 0.5657353401184082\n",
      "In epoch 50, loss: 0.5518573522567749\n",
      "In epoch 55, loss: 0.5376840829849243\n",
      "In epoch 60, loss: 0.5238639116287231\n",
      "In epoch 65, loss: 0.5103583931922913\n",
      "In epoch 70, loss: 0.4968482255935669\n",
      "In epoch 75, loss: 0.48375794291496277\n",
      "In epoch 80, loss: 0.4703128933906555\n",
      "In epoch 85, loss: 0.4572541117668152\n",
      "In epoch 90, loss: 0.444673091173172\n",
      "In epoch 95, loss: 0.4319523870944977\n",
      "In epoch 100, loss: 0.41902974247932434\n",
      "AUC 0.6911229523514377\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(100, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphEVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphEVE(train_g.ndata[\"x\"].shape[1], 32)\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 2.2132632732391357\n",
      "In epoch 10, loss: 1.2318150997161865\n",
      "In epoch 15, loss: 0.9657252430915833\n",
      "In epoch 20, loss: 0.8029099106788635\n",
      "In epoch 25, loss: 0.7689588665962219\n",
      "In epoch 30, loss: 0.7458599805831909\n",
      "In epoch 35, loss: 0.727140486240387\n",
      "In epoch 40, loss: 0.7140553593635559\n",
      "In epoch 45, loss: 0.7047894597053528\n",
      "In epoch 50, loss: 0.6962063908576965\n",
      "In epoch 55, loss: 0.6883410215377808\n",
      "In epoch 60, loss: 0.6820026636123657\n",
      "In epoch 65, loss: 0.6768398880958557\n",
      "In epoch 70, loss: 0.6719354391098022\n",
      "In epoch 75, loss: 0.6674953103065491\n",
      "In epoch 80, loss: 0.6633650660514832\n",
      "In epoch 85, loss: 0.6592849493026733\n",
      "In epoch 90, loss: 0.655174195766449\n",
      "In epoch 95, loss: 0.6509707570075989\n",
      "In epoch 100, loss: 0.6466691493988037\n",
      "AUC 0.7213066043408167\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(100, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
