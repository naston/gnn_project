{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid, Actor\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from copy import deepcopy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/'.join(os.getcwd().split('/')[:-2]))\n",
    "from src import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cora model:\n",
    "cora = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(cora[0])\n",
    "\n",
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32)\n",
    "pred = MLPPredictor(32)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6881262063980103\n",
      "In epoch 10, loss: 0.64781653881073\n",
      "In epoch 15, loss: 0.5861732959747314\n",
      "In epoch 20, loss: 0.5601806640625\n",
      "In epoch 25, loss: 0.5454561710357666\n",
      "In epoch 30, loss: 0.5283210277557373\n",
      "In epoch 35, loss: 0.5114594101905823\n",
      "In epoch 40, loss: 0.4908011257648468\n",
      "In epoch 45, loss: 0.47150540351867676\n",
      "In epoch 50, loss: 0.44645392894744873\n",
      "In epoch 55, loss: 0.419136643409729\n",
      "In epoch 60, loss: 0.39415863156318665\n",
      "In epoch 65, loss: 0.3690391480922699\n",
      "In epoch 70, loss: 0.35145696997642517\n",
      "In epoch 75, loss: 0.3312009871006012\n",
      "In epoch 80, loss: 0.31218698620796204\n",
      "In epoch 85, loss: 0.29176223278045654\n",
      "In epoch 90, loss: 0.2872620224952698\n",
      "In epoch 95, loss: 0.27275702357292175\n",
      "In epoch 100, loss: 0.25841566920280457\n",
      "AUC 0.802616293434559\n",
      "In epoch 105, loss: 0.24204814434051514\n",
      "In epoch 110, loss: 0.23821844160556793\n",
      "In epoch 115, loss: 0.22772371768951416\n",
      "In epoch 120, loss: 0.21526092290878296\n",
      "In epoch 125, loss: 0.21264280378818512\n",
      "In epoch 130, loss: 0.1996697634458542\n",
      "In epoch 135, loss: 0.20687121152877808\n",
      "In epoch 140, loss: 0.19327111542224884\n",
      "In epoch 145, loss: 0.18304693698883057\n",
      "In epoch 150, loss: 0.1747397482395172\n",
      "In epoch 155, loss: 0.16593383252620697\n",
      "In epoch 160, loss: 0.1666167676448822\n",
      "In epoch 165, loss: 0.15652592480182648\n",
      "In epoch 170, loss: 0.14809876680374146\n",
      "In epoch 175, loss: 0.13923321664333344\n",
      "In epoch 180, loss: 0.13051460683345795\n",
      "In epoch 185, loss: 0.12311823666095734\n",
      "In epoch 190, loss: 0.1158091127872467\n",
      "In epoch 195, loss: 0.1092481017112732\n",
      "In epoch 200, loss: 0.11704723536968231\n",
      "AUC 0.8437474450259428\n",
      "In epoch 205, loss: 0.10461887717247009\n",
      "In epoch 210, loss: 0.09818559139966965\n",
      "In epoch 215, loss: 0.09263552725315094\n",
      "In epoch 220, loss: 0.08780071139335632\n",
      "In epoch 225, loss: 0.08208458125591278\n",
      "In epoch 230, loss: 0.08175592869520187\n",
      "In epoch 235, loss: 0.07632964849472046\n",
      "In epoch 240, loss: 0.07545504719018936\n",
      "In epoch 245, loss: 0.07177943736314774\n",
      "In epoch 250, loss: 0.06915217638015747\n",
      "In epoch 255, loss: 0.07062364369630814\n",
      "In epoch 260, loss: 0.06310781091451645\n",
      "In epoch 265, loss: 0.06295276433229446\n",
      "In epoch 270, loss: 0.05977930873632431\n",
      "In epoch 275, loss: 0.05890979617834091\n",
      "In epoch 280, loss: 0.056277818977832794\n",
      "In epoch 285, loss: 0.05659503862261772\n",
      "In epoch 290, loss: 0.053416572511196136\n",
      "In epoch 295, loss: 0.05379480496048927\n",
      "In epoch 300, loss: 0.049648284912109375\n",
      "AUC 0.8578369758091687\n",
      "In epoch 305, loss: 0.04952549561858177\n",
      "In epoch 310, loss: 0.050372105091810226\n",
      "In epoch 315, loss: 0.04695327207446098\n",
      "In epoch 320, loss: 0.04637805372476578\n",
      "In epoch 325, loss: 0.04372488334774971\n",
      "In epoch 330, loss: 0.04559774696826935\n",
      "In epoch 335, loss: 0.042934853583574295\n",
      "In epoch 340, loss: 0.04184013232588768\n",
      "In epoch 345, loss: 0.03968387842178345\n",
      "In epoch 350, loss: 0.0398259162902832\n",
      "In epoch 355, loss: 0.04038616269826889\n",
      "In epoch 360, loss: 0.03697892278432846\n",
      "In epoch 365, loss: 0.03943924978375435\n",
      "In epoch 370, loss: 0.035267170518636703\n",
      "In epoch 375, loss: 0.03681882470846176\n",
      "In epoch 380, loss: 0.033808425068855286\n",
      "In epoch 385, loss: 0.035393375903367996\n",
      "In epoch 390, loss: 0.03235449641942978\n",
      "In epoch 395, loss: 0.03394539654254913\n",
      "In epoch 400, loss: 0.031806692481040955\n",
      "AUC 0.8612349228453987\n",
      "In epoch 405, loss: 0.032873861491680145\n",
      "In epoch 410, loss: 0.030084475874900818\n",
      "In epoch 415, loss: 0.03127430006861687\n",
      "In epoch 420, loss: 0.029250018298625946\n",
      "In epoch 425, loss: 0.030768226832151413\n",
      "In epoch 430, loss: 0.027879521250724792\n",
      "In epoch 435, loss: 0.028655681759119034\n",
      "In epoch 440, loss: 0.026769982650876045\n",
      "In epoch 445, loss: 0.027119148522615433\n",
      "In epoch 450, loss: 0.027706434950232506\n",
      "In epoch 455, loss: 0.02539452537894249\n",
      "In epoch 460, loss: 0.027413617819547653\n",
      "In epoch 465, loss: 0.024510104209184647\n",
      "In epoch 470, loss: 0.02619880996644497\n",
      "In epoch 475, loss: 0.02377955988049507\n",
      "In epoch 480, loss: 0.025820663198828697\n",
      "In epoch 485, loss: 0.023199589923024178\n",
      "In epoch 490, loss: 0.02469612844288349\n",
      "In epoch 495, loss: 0.022975027561187744\n",
      "In epoch 500, loss: 0.02465042658150196\n",
      "AUC 0.8610678106960761\n",
      "In epoch 505, loss: 0.02252798154950142\n",
      "In epoch 510, loss: 0.023691004142165184\n",
      "In epoch 515, loss: 0.022144563496112823\n",
      "In epoch 520, loss: 0.023622609674930573\n",
      "In epoch 525, loss: 0.02207304909825325\n",
      "In epoch 530, loss: 0.02277335897088051\n",
      "In epoch 535, loss: 0.02209804207086563\n",
      "In epoch 540, loss: 0.022420838475227356\n",
      "In epoch 545, loss: 0.022352173924446106\n",
      "In epoch 550, loss: 0.021858662366867065\n",
      "In epoch 555, loss: 0.02210949920117855\n",
      "In epoch 560, loss: 0.021625904366374016\n",
      "In epoch 565, loss: 0.021817553788423538\n",
      "In epoch 570, loss: 0.020870082080364227\n",
      "In epoch 575, loss: 0.022285262122750282\n",
      "In epoch 580, loss: 0.020632630214095116\n",
      "In epoch 585, loss: 0.021537913009524345\n",
      "In epoch 590, loss: 0.020266102626919746\n",
      "In epoch 595, loss: 0.02179199457168579\n",
      "In epoch 600, loss: 0.01987544633448124\n",
      "AUC 0.8595557152804294\n",
      "In epoch 605, loss: 0.021579483523964882\n",
      "In epoch 610, loss: 0.019583512097597122\n",
      "In epoch 615, loss: 0.0217027235776186\n",
      "In epoch 620, loss: 0.0194722767919302\n",
      "In epoch 625, loss: 0.02122308872640133\n",
      "In epoch 630, loss: 0.0193414818495512\n",
      "In epoch 635, loss: 0.0209597647190094\n",
      "In epoch 640, loss: 0.019209804013371468\n",
      "In epoch 645, loss: 0.020845700055360794\n",
      "In epoch 650, loss: 0.01895085722208023\n",
      "In epoch 655, loss: 0.020913060754537582\n",
      "In epoch 660, loss: 0.018877660855650902\n",
      "In epoch 665, loss: 0.020556623116135597\n",
      "In epoch 670, loss: 0.01866304501891136\n",
      "In epoch 675, loss: 0.02079172432422638\n",
      "In epoch 680, loss: 0.01856338046491146\n",
      "In epoch 685, loss: 0.020243007689714432\n",
      "In epoch 690, loss: 0.018415475264191628\n",
      "In epoch 695, loss: 0.020620767027139664\n",
      "In epoch 700, loss: 0.01829698495566845\n",
      "AUC 0.8595503245659353\n",
      "In epoch 705, loss: 0.019891995936632156\n",
      "In epoch 710, loss: 0.018099719658493996\n",
      "In epoch 715, loss: 0.019913602620363235\n",
      "In epoch 720, loss: 0.017934761941432953\n",
      "In epoch 725, loss: 0.019444353878498077\n",
      "In epoch 730, loss: 0.01790163479745388\n",
      "In epoch 735, loss: 0.01968776248395443\n",
      "In epoch 740, loss: 0.017802713438868523\n",
      "In epoch 745, loss: 0.01918923296034336\n",
      "In epoch 750, loss: 0.01779353804886341\n",
      "In epoch 755, loss: 0.01942453347146511\n",
      "In epoch 760, loss: 0.017880668863654137\n",
      "In epoch 765, loss: 0.01903611049056053\n",
      "In epoch 770, loss: 0.01783856749534607\n",
      "In epoch 775, loss: 0.019316526129841805\n",
      "In epoch 780, loss: 0.017797086387872696\n",
      "In epoch 785, loss: 0.018938271328806877\n",
      "In epoch 790, loss: 0.017790542915463448\n",
      "In epoch 795, loss: 0.019126351922750473\n",
      "In epoch 800, loss: 0.01770985685288906\n",
      "AUC 0.8599672064868263\n",
      "In epoch 805, loss: 0.01872124895453453\n",
      "In epoch 810, loss: 0.017824551090598106\n",
      "In epoch 815, loss: 0.018984274938702583\n",
      "In epoch 820, loss: 0.017748886719346046\n",
      "In epoch 825, loss: 0.018712816759943962\n",
      "In epoch 830, loss: 0.017636485397815704\n",
      "In epoch 835, loss: 0.019014613702893257\n",
      "In epoch 840, loss: 0.01757405512034893\n",
      "In epoch 845, loss: 0.018682513386011124\n",
      "In epoch 850, loss: 0.017516791820526123\n",
      "In epoch 855, loss: 0.018926838412880898\n",
      "In epoch 860, loss: 0.017511432990431786\n",
      "In epoch 865, loss: 0.018506411463022232\n",
      "In epoch 870, loss: 0.017547357827425003\n",
      "In epoch 875, loss: 0.01869748719036579\n",
      "In epoch 880, loss: 0.01764741912484169\n",
      "In epoch 885, loss: 0.018420232459902763\n",
      "In epoch 890, loss: 0.017551705241203308\n",
      "In epoch 895, loss: 0.01852118782699108\n",
      "In epoch 900, loss: 0.017136484384536743\n",
      "AUC 0.860288852451652\n",
      "In epoch 905, loss: 0.017917165532708168\n",
      "In epoch 910, loss: 0.017289718613028526\n",
      "In epoch 915, loss: 0.018071476370096207\n",
      "In epoch 920, loss: 0.016805225983262062\n",
      "In epoch 925, loss: 0.01767825521528721\n",
      "In epoch 930, loss: 0.016587400808930397\n",
      "In epoch 935, loss: 0.017623988911509514\n",
      "In epoch 940, loss: 0.016613246873021126\n",
      "In epoch 945, loss: 0.017275495454669\n",
      "In epoch 950, loss: 0.016970504075288773\n",
      "In epoch 955, loss: 0.017198950052261353\n",
      "In epoch 960, loss: 0.01719450019299984\n",
      "In epoch 965, loss: 0.016952497884631157\n",
      "In epoch 970, loss: 0.017581768333911896\n",
      "In epoch 975, loss: 0.01698465086519718\n",
      "In epoch 980, loss: 0.017326658591628075\n",
      "In epoch 985, loss: 0.01685497537255287\n",
      "In epoch 990, loss: 0.01759977824985981\n",
      "In epoch 995, loss: 0.016861524432897568\n",
      "In epoch 1000, loss: 0.017458196729421616\n",
      "AUC 0.8609797623593359\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='pool')\n",
    "pred = MLPPredictor(32)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6897978186607361\n",
      "In epoch 10, loss: 0.6589993238449097\n",
      "In epoch 15, loss: 0.5966556072235107\n",
      "In epoch 20, loss: 0.5643706917762756\n",
      "In epoch 25, loss: 0.543643057346344\n",
      "In epoch 30, loss: 0.5310526490211487\n",
      "In epoch 35, loss: 0.5145068168640137\n",
      "In epoch 40, loss: 0.5015579462051392\n",
      "In epoch 45, loss: 0.48903724551200867\n",
      "In epoch 50, loss: 0.4756827652454376\n",
      "In epoch 55, loss: 0.4582759737968445\n",
      "In epoch 60, loss: 0.4319886565208435\n",
      "In epoch 65, loss: 0.42698249220848083\n",
      "In epoch 70, loss: 0.38241657614707947\n",
      "In epoch 75, loss: 0.3673381507396698\n",
      "In epoch 80, loss: 0.33755603432655334\n",
      "In epoch 85, loss: 0.3145856261253357\n",
      "In epoch 90, loss: 0.29491522908210754\n",
      "In epoch 95, loss: 0.2786233723163605\n",
      "In epoch 100, loss: 0.26284417510032654\n",
      "AUC 0.7924314368500258\n",
      "In epoch 105, loss: 0.2461032122373581\n",
      "In epoch 110, loss: 0.23793070018291473\n",
      "In epoch 115, loss: 0.2817286252975464\n",
      "In epoch 120, loss: 0.22139926254749298\n",
      "In epoch 125, loss: 0.21593394875526428\n",
      "In epoch 130, loss: 0.20867985486984253\n",
      "In epoch 135, loss: 0.19493140280246735\n",
      "In epoch 140, loss: 0.18323075771331787\n",
      "In epoch 145, loss: 0.1771809309720993\n",
      "In epoch 150, loss: 0.17184805870056152\n",
      "In epoch 155, loss: 0.16565647721290588\n",
      "In epoch 160, loss: 0.1614004373550415\n",
      "In epoch 165, loss: 0.15971247851848602\n",
      "In epoch 170, loss: 0.15339548885822296\n",
      "In epoch 175, loss: 0.150072380900383\n",
      "In epoch 180, loss: 0.14687564969062805\n",
      "In epoch 185, loss: 0.14634335041046143\n",
      "In epoch 190, loss: 0.1403132975101471\n",
      "In epoch 195, loss: 0.1341456174850464\n",
      "In epoch 200, loss: 0.1281748116016388\n",
      "AUC 0.8362696255699558\n",
      "In epoch 205, loss: 0.12839572131633759\n",
      "In epoch 210, loss: 0.12658606469631195\n",
      "In epoch 215, loss: 0.11929144710302353\n",
      "In epoch 220, loss: 0.11094531416893005\n",
      "In epoch 225, loss: 0.10642844438552856\n",
      "In epoch 230, loss: 0.10331639647483826\n",
      "In epoch 235, loss: 0.10026820003986359\n",
      "In epoch 240, loss: 0.09601569175720215\n",
      "In epoch 245, loss: 0.09095008671283722\n",
      "In epoch 250, loss: 0.08620753139257431\n",
      "In epoch 255, loss: 0.08207982033491135\n",
      "In epoch 260, loss: 0.0785195603966713\n",
      "In epoch 265, loss: 0.07516441494226456\n",
      "In epoch 270, loss: 0.07107999175786972\n",
      "In epoch 275, loss: 0.06733778864145279\n",
      "In epoch 280, loss: 0.06325633823871613\n",
      "In epoch 285, loss: 0.059048060327768326\n",
      "In epoch 290, loss: 0.05454643443226814\n",
      "In epoch 295, loss: 0.050708621740341187\n",
      "In epoch 300, loss: 0.04808579012751579\n",
      "AUC 0.8364672851014129\n",
      "In epoch 305, loss: 0.04656221345067024\n",
      "In epoch 310, loss: 0.0440678633749485\n",
      "In epoch 315, loss: 0.04081915318965912\n",
      "In epoch 320, loss: 0.038458868861198425\n",
      "In epoch 325, loss: 0.035215333104133606\n",
      "In epoch 330, loss: 0.032687343657016754\n",
      "In epoch 335, loss: 0.030919281765818596\n",
      "In epoch 340, loss: 0.0289335735142231\n",
      "In epoch 345, loss: 0.02728520706295967\n",
      "In epoch 350, loss: 0.0265674889087677\n",
      "In epoch 355, loss: 0.027131633833050728\n",
      "In epoch 360, loss: 0.023905616253614426\n",
      "In epoch 365, loss: 0.022079626098275185\n",
      "In epoch 370, loss: 0.021200601011514664\n",
      "In epoch 375, loss: 0.02022075094282627\n",
      "In epoch 380, loss: 0.019195329397916794\n",
      "In epoch 385, loss: 0.018631605431437492\n",
      "In epoch 390, loss: 0.018710821866989136\n",
      "In epoch 395, loss: 0.017942773178219795\n",
      "In epoch 400, loss: 0.016474677249789238\n",
      "AUC 0.8366927966577571\n",
      "In epoch 405, loss: 0.015336443670094013\n",
      "In epoch 410, loss: 0.014474871568381786\n",
      "In epoch 415, loss: 0.014226350001990795\n",
      "In epoch 420, loss: 0.013583816587924957\n",
      "In epoch 425, loss: 0.012799030169844627\n",
      "In epoch 430, loss: 0.01241312175989151\n",
      "In epoch 435, loss: 0.011902498081326485\n",
      "In epoch 440, loss: 0.011343169026076794\n",
      "In epoch 445, loss: 0.011139016598463058\n",
      "In epoch 450, loss: 0.010488496161997318\n",
      "In epoch 455, loss: 0.010108426213264465\n",
      "In epoch 460, loss: 0.009747552685439587\n",
      "In epoch 465, loss: 0.009268813766539097\n",
      "In epoch 470, loss: 0.00892724934965372\n",
      "In epoch 475, loss: 0.008649513125419617\n",
      "In epoch 480, loss: 0.008493363857269287\n",
      "In epoch 485, loss: 0.009328828193247318\n",
      "In epoch 490, loss: 0.008673932403326035\n",
      "In epoch 495, loss: 0.008059727028012276\n",
      "In epoch 500, loss: 0.007500654552131891\n",
      "AUC 0.8387556434042363\n",
      "In epoch 505, loss: 0.007175827398896217\n",
      "In epoch 510, loss: 0.007014602422714233\n",
      "In epoch 515, loss: 0.006650063209235668\n",
      "In epoch 520, loss: 0.006444480735808611\n",
      "In epoch 525, loss: 0.006467823404818773\n",
      "In epoch 530, loss: 0.006066706031560898\n",
      "In epoch 535, loss: 0.006437292788177729\n",
      "In epoch 540, loss: 0.005885448772460222\n",
      "In epoch 545, loss: 0.0058168331161141396\n",
      "In epoch 550, loss: 0.0056593832559883595\n",
      "In epoch 555, loss: 0.005649837199598551\n",
      "In epoch 560, loss: 0.00532137043774128\n",
      "In epoch 565, loss: 0.005545079708099365\n",
      "In epoch 570, loss: 0.0050828480161726475\n",
      "In epoch 575, loss: 0.005159598775207996\n",
      "In epoch 580, loss: 0.00495520792901516\n",
      "In epoch 585, loss: 0.004722656216472387\n",
      "In epoch 590, loss: 0.0046078599989414215\n",
      "In epoch 595, loss: 0.004646490793675184\n",
      "In epoch 600, loss: 0.00511236023157835\n",
      "AUC 0.8371258507221312\n",
      "In epoch 605, loss: 0.004993355832993984\n",
      "In epoch 610, loss: 0.004686031024903059\n",
      "In epoch 615, loss: 0.0044640726409852505\n",
      "In epoch 620, loss: 0.004247110802680254\n",
      "In epoch 625, loss: 0.004311023745685816\n",
      "In epoch 630, loss: 0.004510756116360426\n",
      "In epoch 635, loss: 0.0041872779838740826\n",
      "In epoch 640, loss: 0.004025264643132687\n",
      "In epoch 645, loss: 0.004100499674677849\n",
      "In epoch 650, loss: 0.004654027055948973\n",
      "In epoch 655, loss: 0.004478043410927057\n",
      "In epoch 660, loss: 0.004111341200768948\n",
      "In epoch 665, loss: 0.003852658672258258\n",
      "In epoch 670, loss: 0.004054783843457699\n",
      "In epoch 675, loss: 0.004092194605618715\n",
      "In epoch 680, loss: 0.0036630271933972836\n",
      "In epoch 685, loss: 0.003661269089207053\n",
      "In epoch 690, loss: 0.0036264590453356504\n",
      "In epoch 695, loss: 0.005450964439660311\n",
      "In epoch 700, loss: 1.152502417564392\n",
      "AUC 0.7995283124817503\n",
      "In epoch 705, loss: 2.281595468521118\n",
      "In epoch 710, loss: 1.1081254482269287\n",
      "In epoch 715, loss: 0.7102024555206299\n",
      "In epoch 720, loss: 0.46623191237449646\n",
      "In epoch 725, loss: 0.41351890563964844\n",
      "In epoch 730, loss: 0.3894900381565094\n",
      "In epoch 735, loss: 0.34760594367980957\n",
      "In epoch 740, loss: 0.32324662804603577\n",
      "In epoch 745, loss: 0.30189448595046997\n",
      "In epoch 750, loss: 0.28432488441467285\n",
      "In epoch 755, loss: 0.2700958251953125\n",
      "In epoch 760, loss: 0.25762614607810974\n",
      "In epoch 765, loss: 0.2468198835849762\n",
      "In epoch 770, loss: 0.23745030164718628\n",
      "In epoch 775, loss: 0.22917306423187256\n",
      "In epoch 780, loss: 0.22167691588401794\n",
      "In epoch 785, loss: 0.21478351950645447\n",
      "In epoch 790, loss: 0.2084684520959854\n",
      "In epoch 795, loss: 0.20270049571990967\n",
      "In epoch 800, loss: 0.19736923277378082\n",
      "AUC 0.8336164955863525\n",
      "In epoch 805, loss: 0.1924070119857788\n",
      "In epoch 810, loss: 0.1877516657114029\n",
      "In epoch 815, loss: 0.18339264392852783\n",
      "In epoch 820, loss: 0.17912256717681885\n",
      "In epoch 825, loss: 0.17496754229068756\n",
      "In epoch 830, loss: 0.1710115224123001\n",
      "In epoch 835, loss: 0.16719329357147217\n",
      "In epoch 840, loss: 0.16362757980823517\n",
      "In epoch 845, loss: 0.16022755205631256\n",
      "In epoch 850, loss: 0.1568855345249176\n",
      "In epoch 855, loss: 0.1535699963569641\n",
      "In epoch 860, loss: 0.15026316046714783\n",
      "In epoch 865, loss: 0.1470811665058136\n",
      "In epoch 870, loss: 0.14394345879554749\n",
      "In epoch 875, loss: 0.14092350006103516\n",
      "In epoch 880, loss: 0.13794630765914917\n",
      "In epoch 885, loss: 0.13495436310768127\n",
      "In epoch 890, loss: 0.1320357769727707\n",
      "In epoch 895, loss: 0.12923993170261383\n",
      "In epoch 900, loss: 0.12656170129776\n",
      "AUC 0.8515469104467555\n",
      "In epoch 905, loss: 0.12400245666503906\n",
      "In epoch 910, loss: 0.12147698551416397\n",
      "In epoch 915, loss: 0.1190563514828682\n",
      "In epoch 920, loss: 0.11669310182332993\n",
      "In epoch 925, loss: 0.1143580824136734\n",
      "In epoch 930, loss: 0.11209289729595184\n",
      "In epoch 935, loss: 0.10989644378423691\n",
      "In epoch 940, loss: 0.10775388777256012\n",
      "In epoch 945, loss: 0.10562357306480408\n",
      "In epoch 950, loss: 0.10331865400075912\n",
      "In epoch 955, loss: 0.10098075121641159\n",
      "In epoch 960, loss: 0.0988987535238266\n",
      "In epoch 965, loss: 0.0968928262591362\n",
      "In epoch 970, loss: 0.09489275515079498\n",
      "In epoch 975, loss: 0.09289723634719849\n",
      "In epoch 980, loss: 0.09094466269016266\n",
      "In epoch 985, loss: 0.08904001116752625\n",
      "In epoch 990, loss: 0.08696606010198593\n",
      "In epoch 995, loss: 0.0850074514746666\n",
      "In epoch 1000, loss: 0.08327627182006836\n",
      "AUC 0.8619195435861728\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='lstm')\n",
    "pred = MLPPredictor(32)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6883365511894226\n",
      "In epoch 10, loss: 0.6506872773170471\n",
      "In epoch 15, loss: 0.5944363474845886\n",
      "In epoch 20, loss: 0.557481586933136\n",
      "In epoch 25, loss: 0.533795177936554\n",
      "In epoch 30, loss: 0.5168571472167969\n",
      "In epoch 35, loss: 0.49965983629226685\n",
      "In epoch 40, loss: 0.48354214429855347\n",
      "In epoch 45, loss: 0.4647616744041443\n",
      "In epoch 50, loss: 0.44313862919807434\n",
      "In epoch 55, loss: 0.42548108100891113\n",
      "In epoch 60, loss: 0.3932667076587677\n",
      "In epoch 65, loss: 0.36693188548088074\n",
      "In epoch 70, loss: 0.34153419733047485\n",
      "In epoch 75, loss: 0.31989893317222595\n",
      "In epoch 80, loss: 0.3068668842315674\n",
      "In epoch 85, loss: 0.29772743582725525\n",
      "In epoch 90, loss: 0.2787810266017914\n",
      "In epoch 95, loss: 0.2638188600540161\n",
      "In epoch 100, loss: 0.25307178497314453\n",
      "AUC 0.7940109161968509\n",
      "In epoch 105, loss: 0.24520859122276306\n",
      "In epoch 110, loss: 0.2375347763299942\n",
      "In epoch 115, loss: 0.22642888128757477\n",
      "In epoch 120, loss: 0.22982603311538696\n",
      "In epoch 125, loss: 0.21471457183361053\n",
      "In epoch 130, loss: 0.2070096731185913\n",
      "In epoch 135, loss: 0.20297059416770935\n",
      "In epoch 140, loss: 0.19769863784313202\n",
      "In epoch 145, loss: 0.19490185379981995\n",
      "In epoch 150, loss: 0.18984073400497437\n",
      "In epoch 155, loss: 0.18282216787338257\n",
      "In epoch 160, loss: 0.17978328466415405\n",
      "In epoch 165, loss: 0.19462239742279053\n",
      "In epoch 170, loss: 0.2093333750963211\n",
      "In epoch 175, loss: 0.1855141669511795\n",
      "In epoch 180, loss: 0.18766842782497406\n",
      "In epoch 185, loss: 0.17369745671749115\n",
      "In epoch 190, loss: 0.1637600064277649\n",
      "In epoch 195, loss: 0.1587369590997696\n",
      "In epoch 200, loss: 0.1544395089149475\n",
      "AUC 0.8268673210395093\n",
      "In epoch 205, loss: 0.15053577721118927\n",
      "In epoch 210, loss: 0.14464284479618073\n",
      "In epoch 215, loss: 0.14076678454875946\n",
      "In epoch 220, loss: 0.13682503998279572\n",
      "In epoch 225, loss: 0.13313044607639313\n",
      "In epoch 230, loss: 0.1356709599494934\n",
      "In epoch 235, loss: 0.13709022104740143\n",
      "In epoch 240, loss: 0.1246790885925293\n",
      "In epoch 245, loss: 0.12178406864404678\n",
      "In epoch 250, loss: 0.11619248986244202\n",
      "In epoch 255, loss: 0.11274729669094086\n",
      "In epoch 260, loss: 0.11126194149255753\n",
      "In epoch 265, loss: 0.10818912833929062\n",
      "In epoch 270, loss: 0.10655125975608826\n",
      "In epoch 275, loss: 0.10302478820085526\n",
      "In epoch 280, loss: 0.09886308014392853\n",
      "In epoch 285, loss: 0.09456674754619598\n",
      "In epoch 290, loss: 0.09315310418605804\n",
      "In epoch 295, loss: 0.093789242208004\n",
      "In epoch 300, loss: 0.09538672864437103\n",
      "AUC 0.8416908874463734\n",
      "In epoch 305, loss: 0.08639011532068253\n",
      "In epoch 310, loss: 0.08448099344968796\n",
      "In epoch 315, loss: 0.0806572213768959\n",
      "In epoch 320, loss: 0.0796380266547203\n",
      "In epoch 325, loss: 0.07648702710866928\n",
      "In epoch 330, loss: 0.07577741146087646\n",
      "In epoch 335, loss: 0.07233256101608276\n",
      "In epoch 340, loss: 0.07049014419317245\n",
      "In epoch 345, loss: 0.06881267577409744\n",
      "In epoch 350, loss: 0.06794852763414383\n",
      "In epoch 355, loss: 0.06594996899366379\n",
      "In epoch 360, loss: 0.06445810943841934\n",
      "In epoch 365, loss: 0.06326985359191895\n",
      "In epoch 370, loss: 0.06237766146659851\n",
      "In epoch 375, loss: 0.06159299239516258\n",
      "In epoch 380, loss: 0.06085219979286194\n",
      "In epoch 385, loss: 0.0601758137345314\n",
      "In epoch 390, loss: 0.05897775664925575\n",
      "In epoch 395, loss: 0.058435339480638504\n",
      "In epoch 400, loss: 0.0582871288061142\n",
      "AUC 0.8444653085060982\n",
      "In epoch 405, loss: 0.057314980775117874\n",
      "In epoch 410, loss: 0.05622701719403267\n",
      "In epoch 415, loss: 0.05596976354718208\n",
      "In epoch 420, loss: 0.055370982736349106\n",
      "In epoch 425, loss: 0.05489348620176315\n",
      "In epoch 430, loss: 0.05441853031516075\n",
      "In epoch 435, loss: 0.05479910597205162\n",
      "In epoch 440, loss: 0.05350656062364578\n",
      "In epoch 445, loss: 0.05298975110054016\n",
      "In epoch 450, loss: 0.05424840748310089\n",
      "In epoch 455, loss: 0.05187741294503212\n",
      "In epoch 460, loss: 0.05192439258098602\n",
      "In epoch 465, loss: 0.056829504668712616\n",
      "In epoch 470, loss: 0.05761474743485451\n",
      "In epoch 475, loss: 0.056243058294057846\n",
      "In epoch 480, loss: 0.0507698580622673\n",
      "In epoch 485, loss: 0.05128052458167076\n",
      "In epoch 490, loss: 0.04896548017859459\n",
      "In epoch 495, loss: 0.04838501289486885\n",
      "In epoch 500, loss: 0.047618940472602844\n",
      "AUC 0.8475901260079516\n",
      "In epoch 505, loss: 0.04655341058969498\n",
      "In epoch 510, loss: 0.04566188156604767\n",
      "In epoch 515, loss: 0.04476575553417206\n",
      "In epoch 520, loss: 0.04360727593302727\n",
      "In epoch 525, loss: 0.043143391609191895\n",
      "In epoch 530, loss: 0.04405311495065689\n",
      "In epoch 535, loss: 0.04218824580311775\n",
      "In epoch 540, loss: 0.03929637745022774\n",
      "In epoch 545, loss: 0.0383908636868\n",
      "In epoch 550, loss: 0.03989291563630104\n",
      "In epoch 555, loss: 0.037556242197752\n",
      "In epoch 560, loss: 0.03328186646103859\n",
      "In epoch 565, loss: 0.09241467714309692\n",
      "In epoch 570, loss: 1.8803045749664307\n",
      "In epoch 575, loss: 0.6402716636657715\n",
      "In epoch 580, loss: 0.5869719982147217\n",
      "In epoch 585, loss: 0.550860583782196\n",
      "In epoch 590, loss: 0.5125027298927307\n",
      "In epoch 595, loss: 0.4827229976654053\n",
      "In epoch 600, loss: 0.4369962513446808\n",
      "AUC 0.7694580085802205\n",
      "In epoch 605, loss: 0.41049858927726746\n",
      "In epoch 610, loss: 0.38768893480300903\n",
      "In epoch 615, loss: 0.3678531348705292\n",
      "In epoch 620, loss: 0.35281121730804443\n",
      "In epoch 625, loss: 0.3377641439437866\n",
      "In epoch 630, loss: 0.32435595989227295\n",
      "In epoch 635, loss: 0.31405404210090637\n",
      "In epoch 640, loss: 0.3047178387641907\n",
      "In epoch 645, loss: 0.29701218008995056\n",
      "In epoch 650, loss: 0.28958314657211304\n",
      "In epoch 655, loss: 0.2834075391292572\n",
      "In epoch 660, loss: 0.2777925133705139\n",
      "In epoch 665, loss: 0.27255764603614807\n",
      "In epoch 670, loss: 0.26759475469589233\n",
      "In epoch 675, loss: 0.2628830075263977\n",
      "In epoch 680, loss: 0.25833016633987427\n",
      "In epoch 685, loss: 0.2537573277950287\n",
      "In epoch 690, loss: 0.24917781352996826\n",
      "In epoch 695, loss: 0.24477791786193848\n",
      "In epoch 700, loss: 0.24062089622020721\n",
      "AUC 0.8185251903596056\n",
      "In epoch 705, loss: 0.23653565347194672\n",
      "In epoch 710, loss: 0.23251274228096008\n",
      "In epoch 715, loss: 0.228614941239357\n",
      "In epoch 720, loss: 0.2247808277606964\n",
      "In epoch 725, loss: 0.2210400551557541\n",
      "In epoch 730, loss: 0.21721376478672028\n",
      "In epoch 735, loss: 0.21341288089752197\n",
      "In epoch 740, loss: 0.20954103767871857\n",
      "In epoch 745, loss: 0.2055983990430832\n",
      "In epoch 750, loss: 0.20172062516212463\n",
      "In epoch 755, loss: 0.19800376892089844\n",
      "In epoch 760, loss: 0.19434405863285065\n",
      "In epoch 765, loss: 0.190877765417099\n",
      "In epoch 770, loss: 0.18728767335414886\n",
      "In epoch 775, loss: 0.1838379204273224\n",
      "In epoch 780, loss: 0.1805027723312378\n",
      "In epoch 785, loss: 0.1772032231092453\n",
      "In epoch 790, loss: 0.17396041750907898\n",
      "In epoch 795, loss: 0.17087334394454956\n",
      "In epoch 800, loss: 0.16780340671539307\n",
      "AUC 0.8335495608813819\n",
      "In epoch 805, loss: 0.1648133546113968\n",
      "In epoch 810, loss: 0.1618259996175766\n",
      "In epoch 815, loss: 0.15879282355308533\n",
      "In epoch 820, loss: 0.1558002531528473\n",
      "In epoch 825, loss: 0.15298590064048767\n",
      "In epoch 830, loss: 0.15011635422706604\n",
      "In epoch 835, loss: 0.14728274941444397\n",
      "In epoch 840, loss: 0.1445084661245346\n",
      "In epoch 845, loss: 0.14178597927093506\n",
      "In epoch 850, loss: 0.13901782035827637\n",
      "In epoch 855, loss: 0.13631366193294525\n",
      "In epoch 860, loss: 0.1336490660905838\n",
      "In epoch 865, loss: 0.1310710608959198\n",
      "In epoch 870, loss: 0.12860099971294403\n",
      "In epoch 875, loss: 0.12608636915683746\n",
      "In epoch 880, loss: 0.12351321429014206\n",
      "In epoch 885, loss: 0.12124431878328323\n",
      "In epoch 890, loss: 0.11886869370937347\n",
      "In epoch 895, loss: 0.11641623824834824\n",
      "In epoch 900, loss: 0.11418183147907257\n",
      "AUC 0.8399568742840458\n",
      "In epoch 905, loss: 0.11184398084878922\n",
      "In epoch 910, loss: 0.10937019437551498\n",
      "In epoch 915, loss: 0.10750219225883484\n",
      "In epoch 920, loss: 0.10566159337759018\n",
      "In epoch 925, loss: 0.10316818207502365\n",
      "In epoch 930, loss: 0.10084681212902069\n",
      "In epoch 935, loss: 0.0986531674861908\n",
      "In epoch 940, loss: 0.09680022299289703\n",
      "In epoch 945, loss: 0.0948750227689743\n",
      "In epoch 950, loss: 0.09276743233203888\n",
      "In epoch 955, loss: 0.09139508008956909\n",
      "In epoch 960, loss: 0.0895593911409378\n",
      "In epoch 965, loss: 0.0876021683216095\n",
      "In epoch 970, loss: 0.08608463406562805\n",
      "In epoch 975, loss: 0.08439058065414429\n",
      "In epoch 980, loss: 0.08243457973003387\n",
      "In epoch 985, loss: 0.08366071432828903\n",
      "In epoch 990, loss: 0.08181826025247574\n",
      "In epoch 995, loss: 0.079056017100811\n",
      "In epoch 1000, loss: 0.07721791416406631\n",
      "AUC 0.842141910559062\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN Agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 32, agg='gcn')\n",
    "pred = MLPPredictor(32)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6881817579269409\n",
      "In epoch 10, loss: 0.653206467628479\n",
      "In epoch 15, loss: 0.5981858372688293\n",
      "In epoch 20, loss: 0.5748456716537476\n",
      "In epoch 25, loss: 0.5513438582420349\n",
      "In epoch 30, loss: 0.5288108587265015\n",
      "In epoch 35, loss: 0.5084074139595032\n",
      "In epoch 40, loss: 0.49039632081985474\n",
      "In epoch 45, loss: 0.47301188111305237\n",
      "In epoch 50, loss: 0.45799973607063293\n",
      "In epoch 55, loss: 0.4435465931892395\n",
      "In epoch 60, loss: 0.4325772523880005\n",
      "In epoch 65, loss: 0.42378830909729004\n",
      "In epoch 70, loss: 0.41575106978416443\n",
      "In epoch 75, loss: 0.4000803232192993\n",
      "In epoch 80, loss: 0.39086830615997314\n",
      "In epoch 85, loss: 0.3740013837814331\n",
      "In epoch 90, loss: 0.3617696762084961\n",
      "In epoch 95, loss: 0.34915027022361755\n",
      "In epoch 100, loss: 0.3380183279514313\n",
      "AUC 0.7963477909301228\n",
      "In epoch 105, loss: 0.3275896906852722\n",
      "In epoch 110, loss: 0.3128474950790405\n",
      "In epoch 115, loss: 0.3060632050037384\n",
      "In epoch 120, loss: 0.28964951634407043\n",
      "In epoch 125, loss: 0.2735818922519684\n",
      "In epoch 130, loss: 0.2762567698955536\n",
      "In epoch 135, loss: 0.27362996339797974\n",
      "In epoch 140, loss: 0.24521252512931824\n",
      "In epoch 145, loss: 0.24119479954242706\n",
      "In epoch 150, loss: 0.2294716238975525\n",
      "In epoch 155, loss: 0.22371847927570343\n",
      "In epoch 160, loss: 0.21584662795066833\n",
      "In epoch 165, loss: 0.2084752470254898\n",
      "In epoch 170, loss: 0.20089441537857056\n",
      "In epoch 175, loss: 0.19218142330646515\n",
      "In epoch 180, loss: 0.18994097411632538\n",
      "In epoch 185, loss: 0.19696113467216492\n",
      "In epoch 190, loss: 0.1747005432844162\n",
      "In epoch 195, loss: 0.17304839193820953\n",
      "In epoch 200, loss: 0.16590365767478943\n",
      "AUC 0.8371339367938726\n",
      "In epoch 205, loss: 0.15830209851264954\n",
      "In epoch 210, loss: 0.1525440812110901\n",
      "In epoch 215, loss: 0.1496770828962326\n",
      "In epoch 220, loss: 0.14081993699073792\n",
      "In epoch 225, loss: 0.1383550465106964\n",
      "In epoch 230, loss: 0.137105792760849\n",
      "In epoch 235, loss: 0.12601079046726227\n",
      "In epoch 240, loss: 0.12815681099891663\n",
      "In epoch 245, loss: 0.12126852571964264\n",
      "In epoch 250, loss: 0.11604303866624832\n",
      "In epoch 255, loss: 0.12135965377092361\n",
      "In epoch 260, loss: 0.10930918157100677\n",
      "In epoch 265, loss: 0.10324104130268097\n",
      "In epoch 270, loss: 0.11113256216049194\n",
      "In epoch 275, loss: 0.10838675498962402\n",
      "In epoch 280, loss: 0.09653538465499878\n",
      "In epoch 285, loss: 0.09540203213691711\n",
      "In epoch 290, loss: 0.09044574946165085\n",
      "In epoch 295, loss: 0.08819466829299927\n",
      "In epoch 300, loss: 0.0863330140709877\n",
      "AUC 0.8595134880168909\n",
      "In epoch 305, loss: 0.08209798485040665\n",
      "In epoch 310, loss: 0.08429446071386337\n",
      "In epoch 315, loss: 0.10633618384599686\n",
      "In epoch 320, loss: 0.11183181405067444\n",
      "In epoch 325, loss: 0.08082117885351181\n",
      "In epoch 330, loss: 0.07549473643302917\n",
      "In epoch 335, loss: 0.0761202871799469\n",
      "In epoch 340, loss: 0.07194101810455322\n",
      "In epoch 345, loss: 0.06919912248849869\n",
      "In epoch 350, loss: 0.06757533550262451\n",
      "In epoch 355, loss: 0.06640846282243729\n",
      "In epoch 360, loss: 0.06489086151123047\n",
      "In epoch 365, loss: 0.06341280788183212\n",
      "In epoch 370, loss: 0.06635840237140656\n",
      "In epoch 375, loss: 0.06238311529159546\n",
      "In epoch 380, loss: 0.06393833458423615\n",
      "In epoch 385, loss: 0.06213928759098053\n",
      "In epoch 390, loss: 0.058418020606040955\n",
      "In epoch 395, loss: 0.06284496933221817\n",
      "In epoch 400, loss: 0.059834375977516174\n",
      "AUC 0.8618395813211744\n",
      "In epoch 405, loss: 0.06364396959543228\n",
      "In epoch 410, loss: 0.054953668266534805\n",
      "In epoch 415, loss: 0.052324678748846054\n",
      "In epoch 420, loss: 0.053850505501031876\n",
      "In epoch 425, loss: 0.051457375288009644\n",
      "In epoch 430, loss: 0.0499550886452198\n",
      "In epoch 435, loss: 0.05244649574160576\n",
      "In epoch 440, loss: 0.060632817447185516\n",
      "In epoch 445, loss: 0.05872168019413948\n",
      "In epoch 450, loss: 0.04991829767823219\n",
      "In epoch 455, loss: 0.04836148023605347\n",
      "In epoch 460, loss: 0.04669734463095665\n",
      "In epoch 465, loss: 0.04490913823246956\n",
      "In epoch 470, loss: 0.0438268817961216\n",
      "In epoch 475, loss: 0.04348153620958328\n",
      "In epoch 480, loss: 0.04234647378325462\n",
      "In epoch 485, loss: 0.04231853410601616\n",
      "In epoch 490, loss: 0.04133375734090805\n",
      "In epoch 495, loss: 0.04238208383321762\n",
      "In epoch 500, loss: 0.045482415705919266\n",
      "AUC 0.8634100761438422\n",
      "In epoch 505, loss: 0.04601804539561272\n",
      "In epoch 510, loss: 0.45589351654052734\n",
      "In epoch 515, loss: 0.3932902216911316\n",
      "In epoch 520, loss: 0.2569219768047333\n",
      "In epoch 525, loss: 0.20773708820343018\n",
      "In epoch 530, loss: 0.15291279554367065\n",
      "In epoch 535, loss: 0.10697799921035767\n",
      "In epoch 540, loss: 0.0837162584066391\n",
      "In epoch 545, loss: 0.07371390610933304\n",
      "In epoch 550, loss: 0.06826447695493698\n",
      "In epoch 555, loss: 0.06214410066604614\n",
      "In epoch 560, loss: 0.05659838765859604\n",
      "In epoch 565, loss: 0.05308010056614876\n",
      "In epoch 570, loss: 0.05107119306921959\n",
      "In epoch 575, loss: 0.04966827481985092\n",
      "In epoch 580, loss: 0.048274967819452286\n",
      "In epoch 585, loss: 0.047107186168432236\n",
      "In epoch 590, loss: 0.04599883407354355\n",
      "In epoch 595, loss: 0.04502159729599953\n",
      "In epoch 600, loss: 0.044146157801151276\n",
      "AUC 0.8660757844612654\n",
      "In epoch 605, loss: 0.043343525379896164\n",
      "In epoch 610, loss: 0.042605262249708176\n",
      "In epoch 615, loss: 0.04191558435559273\n",
      "In epoch 620, loss: 0.041265182197093964\n",
      "In epoch 625, loss: 0.04064426198601723\n",
      "In epoch 630, loss: 0.0400647409260273\n",
      "In epoch 635, loss: 0.03950713947415352\n",
      "In epoch 640, loss: 0.03897800296545029\n",
      "In epoch 645, loss: 0.03847121074795723\n",
      "In epoch 650, loss: 0.03797789290547371\n",
      "In epoch 655, loss: 0.037509236484766006\n",
      "In epoch 660, loss: 0.03703358396887779\n",
      "In epoch 665, loss: 0.03657953813672066\n",
      "In epoch 670, loss: 0.03614557161927223\n",
      "In epoch 675, loss: 0.035725757479667664\n",
      "In epoch 680, loss: 0.035324402153491974\n",
      "In epoch 685, loss: 0.034937791526317596\n",
      "In epoch 690, loss: 0.03455708175897598\n",
      "In epoch 695, loss: 0.03419174626469612\n",
      "In epoch 700, loss: 0.03383417800068855\n",
      "AUC 0.8663848520922709\n",
      "In epoch 705, loss: 0.03348420560359955\n",
      "In epoch 710, loss: 0.033142127096652985\n",
      "In epoch 715, loss: 0.032807856798172\n",
      "In epoch 720, loss: 0.03247673064470291\n",
      "In epoch 725, loss: 0.0321483351290226\n",
      "In epoch 730, loss: 0.03182921186089516\n",
      "In epoch 735, loss: 0.03151817247271538\n",
      "In epoch 740, loss: 0.031218428164720535\n",
      "In epoch 745, loss: 0.030917007476091385\n",
      "In epoch 750, loss: 0.030629456043243408\n",
      "In epoch 755, loss: 0.0303417406976223\n",
      "In epoch 760, loss: 0.030063223093748093\n",
      "In epoch 765, loss: 0.029793880879878998\n",
      "In epoch 770, loss: 0.029523897916078568\n",
      "In epoch 775, loss: 0.029262831434607506\n",
      "In epoch 780, loss: 0.029000982642173767\n",
      "In epoch 785, loss: 0.028754791244864464\n",
      "In epoch 790, loss: 0.02850610949099064\n",
      "In epoch 795, loss: 0.02826431766152382\n",
      "In epoch 800, loss: 0.02803226374089718\n",
      "AUC 0.866212349228454\n",
      "In epoch 805, loss: 0.027799945324659348\n",
      "In epoch 810, loss: 0.027577098459005356\n",
      "In epoch 815, loss: 0.027349721640348434\n",
      "In epoch 820, loss: 0.02713738940656185\n",
      "In epoch 825, loss: 0.026926925405859947\n",
      "In epoch 830, loss: 0.02671511471271515\n",
      "In epoch 835, loss: 0.02650454081594944\n",
      "In epoch 840, loss: 0.02629322186112404\n",
      "In epoch 845, loss: 0.026094237342476845\n",
      "In epoch 850, loss: 0.02589472196996212\n",
      "In epoch 855, loss: 0.025703104212880135\n",
      "In epoch 860, loss: 0.025502178817987442\n",
      "In epoch 865, loss: 0.02532130479812622\n",
      "In epoch 870, loss: 0.025143351405858994\n",
      "In epoch 875, loss: 0.024961214512586594\n",
      "In epoch 880, loss: 0.024782326072454453\n",
      "In epoch 885, loss: 0.024609241634607315\n",
      "In epoch 890, loss: 0.02444194070994854\n",
      "In epoch 895, loss: 0.02427048608660698\n",
      "In epoch 900, loss: 0.024103328585624695\n",
      "AUC 0.8653713977673456\n",
      "In epoch 905, loss: 0.023942505940794945\n",
      "In epoch 910, loss: 0.023775316774845123\n",
      "In epoch 915, loss: 0.023611553013324738\n",
      "In epoch 920, loss: 0.023447221145033836\n",
      "In epoch 925, loss: 0.023293882608413696\n",
      "In epoch 930, loss: 0.023104878142476082\n",
      "In epoch 935, loss: 0.022909611463546753\n",
      "In epoch 940, loss: 0.022693032398819923\n",
      "In epoch 945, loss: 0.02244582027196884\n",
      "In epoch 950, loss: 0.02218306064605713\n",
      "In epoch 955, loss: 0.021878328174352646\n",
      "In epoch 960, loss: 0.021604306995868683\n",
      "In epoch 965, loss: 0.021411456167697906\n",
      "In epoch 970, loss: 0.021224409341812134\n",
      "In epoch 975, loss: 0.021022610366344452\n",
      "In epoch 980, loss: 0.020816586911678314\n",
      "In epoch 985, loss: 0.020624257624149323\n",
      "In epoch 990, loss: 0.020448893308639526\n",
      "In epoch 995, loss: 0.02025514841079712\n",
      "In epoch 1000, loss: 0.020053725689649582\n",
      "AUC 0.8653372565755486\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphEVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphEVE(train_g.ndata[\"x\"].shape[1], 32)\n",
    "pred = MLPPredictor(32)\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathan.paull/workspace/gnn_project/src/models.py:136: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorShape.cpp:3618.)\n",
      "  graph.dstdata['eve']=self.relu(self.dw_conv(tt.T).T)[:,:,0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.7084175944328308\n",
      "In epoch 10, loss: 0.6981925964355469\n",
      "In epoch 15, loss: 0.6932471990585327\n",
      "In epoch 20, loss: 0.6938855648040771\n",
      "In epoch 25, loss: 0.6939219832420349\n",
      "In epoch 30, loss: 0.6933499574661255\n",
      "In epoch 35, loss: 0.6932055950164795\n",
      "In epoch 40, loss: 0.6932910680770874\n",
      "In epoch 45, loss: 0.6932910084724426\n",
      "In epoch 50, loss: 0.6932286024093628\n",
      "In epoch 55, loss: 0.6931902170181274\n",
      "In epoch 60, loss: 0.6931816339492798\n",
      "In epoch 65, loss: 0.6931800246238708\n",
      "In epoch 70, loss: 0.6931745409965515\n",
      "In epoch 75, loss: 0.6931652426719666\n",
      "In epoch 80, loss: 0.6931540369987488\n",
      "In epoch 85, loss: 0.6931411623954773\n",
      "In epoch 90, loss: 0.6931257247924805\n",
      "In epoch 95, loss: 0.693105936050415\n",
      "In epoch 100, loss: 0.6930797696113586\n",
      "AUC 0.6892801150019091\n",
      "In epoch 105, loss: 0.6930434107780457\n",
      "In epoch 110, loss: 0.6929918527603149\n",
      "In epoch 115, loss: 0.692916214466095\n",
      "In epoch 120, loss: 0.6928010582923889\n",
      "In epoch 125, loss: 0.6926175355911255\n",
      "In epoch 130, loss: 0.6923073530197144\n",
      "In epoch 135, loss: 0.6917372345924377\n",
      "In epoch 140, loss: 0.6905632019042969\n",
      "In epoch 145, loss: 0.687691330909729\n",
      "In epoch 150, loss: 0.6789284348487854\n",
      "In epoch 155, loss: 0.6531304121017456\n",
      "In epoch 160, loss: 0.6807963848114014\n",
      "In epoch 165, loss: 0.6592803001403809\n",
      "In epoch 170, loss: 0.6176091432571411\n",
      "In epoch 175, loss: 0.6117391586303711\n",
      "In epoch 180, loss: 0.5788311958312988\n",
      "In epoch 185, loss: 0.5675438642501831\n",
      "In epoch 190, loss: 0.5636955499649048\n",
      "In epoch 195, loss: 0.5367184281349182\n",
      "In epoch 200, loss: 0.5228247046470642\n",
      "AUC 0.6778679724175108\n",
      "In epoch 205, loss: 0.5061060190200806\n",
      "In epoch 210, loss: 0.4892772436141968\n",
      "In epoch 215, loss: 0.47412464022636414\n",
      "In epoch 220, loss: 0.4788011610507965\n",
      "In epoch 225, loss: 0.4783257842063904\n",
      "In epoch 230, loss: 0.4540383517742157\n",
      "In epoch 235, loss: 0.437523752450943\n",
      "In epoch 240, loss: 0.4346073269844055\n",
      "In epoch 245, loss: 0.4185948669910431\n",
      "In epoch 250, loss: 0.4393349289894104\n",
      "In epoch 255, loss: 0.4170297384262085\n",
      "In epoch 260, loss: 0.398360013961792\n",
      "In epoch 265, loss: 0.39482417702674866\n",
      "In epoch 270, loss: 0.3827989101409912\n",
      "In epoch 275, loss: 0.43534958362579346\n",
      "In epoch 280, loss: 0.40172079205513\n",
      "In epoch 285, loss: 0.37637704610824585\n",
      "In epoch 290, loss: 0.36872926354408264\n",
      "In epoch 295, loss: 0.3432087302207947\n",
      "In epoch 300, loss: 0.3503451943397522\n",
      "AUC 0.762723209272029\n",
      "In epoch 305, loss: 0.33213114738464355\n",
      "In epoch 310, loss: 0.33233147859573364\n",
      "In epoch 315, loss: 0.3350948393344879\n",
      "In epoch 320, loss: 0.32497069239616394\n",
      "In epoch 325, loss: 0.3095834255218506\n",
      "In epoch 330, loss: 0.3061658442020416\n",
      "In epoch 335, loss: 0.31363382935523987\n",
      "In epoch 340, loss: 0.30788758397102356\n",
      "In epoch 345, loss: 0.2956294119358063\n",
      "In epoch 350, loss: 0.27345511317253113\n",
      "In epoch 355, loss: 0.28274181485176086\n",
      "In epoch 360, loss: 0.26555776596069336\n",
      "In epoch 365, loss: 0.2620275020599365\n",
      "In epoch 370, loss: 0.2837134897708893\n",
      "In epoch 375, loss: 0.26994842290878296\n",
      "In epoch 380, loss: 0.2938614785671234\n",
      "In epoch 385, loss: 0.28148868680000305\n",
      "In epoch 390, loss: 0.25825825333595276\n",
      "In epoch 395, loss: 0.24762672185897827\n",
      "In epoch 400, loss: 0.24238839745521545\n",
      "AUC 0.7959893084162529\n",
      "In epoch 405, loss: 0.2256365567445755\n",
      "In epoch 410, loss: 0.22325430810451508\n",
      "In epoch 415, loss: 0.2184915691614151\n",
      "In epoch 420, loss: 0.21356089413166046\n",
      "In epoch 425, loss: 0.22856426239013672\n",
      "In epoch 430, loss: 0.20360304415225983\n",
      "In epoch 435, loss: 0.20117241144180298\n",
      "In epoch 440, loss: 0.20084328949451447\n",
      "In epoch 445, loss: 0.1913193315267563\n",
      "In epoch 450, loss: 0.20063050091266632\n",
      "In epoch 455, loss: 0.18296952545642853\n",
      "In epoch 460, loss: 0.2652686834335327\n",
      "In epoch 465, loss: 0.2097223401069641\n",
      "In epoch 470, loss: 0.24645249545574188\n",
      "In epoch 475, loss: 0.22616302967071533\n",
      "In epoch 480, loss: 0.22338047623634338\n",
      "In epoch 485, loss: 0.191774383187294\n",
      "In epoch 490, loss: 0.19014135003089905\n",
      "In epoch 495, loss: 0.1733788251876831\n",
      "In epoch 500, loss: 0.17682617902755737\n",
      "AUC 0.8107931088699715\n",
      "In epoch 505, loss: 0.17631033062934875\n",
      "In epoch 510, loss: 0.17316868901252747\n",
      "In epoch 515, loss: 0.1645987331867218\n",
      "In epoch 520, loss: 0.1682097315788269\n",
      "In epoch 525, loss: 0.15058574080467224\n",
      "In epoch 530, loss: 0.33225876092910767\n",
      "In epoch 535, loss: 0.4241945147514343\n",
      "In epoch 540, loss: 0.516014039516449\n",
      "In epoch 545, loss: 0.2667543292045593\n",
      "In epoch 550, loss: 0.2591043710708618\n",
      "In epoch 555, loss: 0.2320035845041275\n",
      "In epoch 560, loss: 0.22074401378631592\n",
      "In epoch 565, loss: 0.20013019442558289\n",
      "In epoch 570, loss: 0.18493787944316864\n",
      "In epoch 575, loss: 0.17770996689796448\n",
      "In epoch 580, loss: 0.17005480825901031\n",
      "In epoch 585, loss: 0.16559933125972748\n",
      "In epoch 590, loss: 0.1614876687526703\n",
      "In epoch 595, loss: 0.1573793739080429\n",
      "In epoch 600, loss: 0.15389606356620789\n",
      "AUC 0.8273318209384335\n",
      "In epoch 605, loss: 0.1509374976158142\n",
      "In epoch 610, loss: 0.1480167806148529\n",
      "In epoch 615, loss: 0.14545711874961853\n",
      "In epoch 620, loss: 0.1430666744709015\n",
      "In epoch 625, loss: 0.14082321524620056\n",
      "In epoch 630, loss: 0.1390249878168106\n",
      "In epoch 635, loss: 0.13785682618618011\n",
      "In epoch 640, loss: 0.13794144988059998\n",
      "In epoch 645, loss: 0.13375437259674072\n",
      "In epoch 650, loss: 0.14801207184791565\n",
      "In epoch 655, loss: 0.13327956199645996\n",
      "In epoch 660, loss: 0.1328178495168686\n",
      "In epoch 665, loss: 0.17370375990867615\n",
      "In epoch 670, loss: 0.19457083940505981\n",
      "In epoch 675, loss: 0.1617988795042038\n",
      "In epoch 680, loss: 0.14155742526054382\n",
      "In epoch 685, loss: 0.12864460051059723\n",
      "In epoch 690, loss: 0.12722933292388916\n",
      "In epoch 695, loss: 0.12618261575698853\n",
      "In epoch 700, loss: 0.12487732619047165\n",
      "AUC 0.833272388311134\n",
      "In epoch 705, loss: 0.12022338807582855\n",
      "In epoch 710, loss: 0.12139283120632172\n",
      "In epoch 715, loss: 0.16425412893295288\n",
      "In epoch 720, loss: 0.12952792644500732\n",
      "In epoch 725, loss: 0.17994901537895203\n",
      "In epoch 730, loss: 0.16008488833904266\n",
      "In epoch 735, loss: 0.14031286537647247\n",
      "In epoch 740, loss: 0.14632557332515717\n",
      "In epoch 745, loss: 0.15272369980812073\n",
      "In epoch 750, loss: 0.15433242917060852\n",
      "In epoch 755, loss: 0.14076454937458038\n",
      "In epoch 760, loss: 0.1398499608039856\n",
      "In epoch 765, loss: 0.12441875040531158\n",
      "In epoch 770, loss: 0.12336587905883789\n",
      "In epoch 775, loss: 0.11528674513101578\n",
      "In epoch 780, loss: 0.11208463460206985\n",
      "In epoch 785, loss: 0.11364421248435974\n",
      "In epoch 790, loss: 0.14383716881275177\n",
      "In epoch 795, loss: 0.12507364153862\n",
      "In epoch 800, loss: 0.10710831731557846\n",
      "AUC 0.8395651490307946\n",
      "In epoch 805, loss: 0.11105050146579742\n",
      "In epoch 810, loss: 0.11157835274934769\n",
      "In epoch 815, loss: 0.10486798733472824\n",
      "In epoch 820, loss: 0.12471485882997513\n",
      "In epoch 825, loss: 0.12424677610397339\n",
      "In epoch 830, loss: 0.2279566526412964\n",
      "In epoch 835, loss: 0.8974004983901978\n",
      "In epoch 840, loss: 0.6557177305221558\n",
      "In epoch 845, loss: 0.5299206376075745\n",
      "In epoch 850, loss: 0.2998564541339874\n",
      "In epoch 855, loss: 0.24085383117198944\n",
      "In epoch 860, loss: 0.21861308813095093\n",
      "In epoch 865, loss: 0.2026408165693283\n",
      "In epoch 870, loss: 0.18746596574783325\n",
      "In epoch 875, loss: 0.17358888685703278\n",
      "In epoch 880, loss: 0.16254982352256775\n",
      "In epoch 885, loss: 0.15295924246311188\n",
      "In epoch 890, loss: 0.1458859145641327\n",
      "In epoch 895, loss: 0.13970033824443817\n",
      "In epoch 900, loss: 0.13444051146507263\n",
      "AUC 0.8363019698569215\n",
      "In epoch 905, loss: 0.12983566522598267\n",
      "In epoch 910, loss: 0.12567810714244843\n",
      "In epoch 915, loss: 0.12186887860298157\n",
      "In epoch 920, loss: 0.11857377737760544\n",
      "In epoch 925, loss: 0.11541543155908585\n",
      "In epoch 930, loss: 0.11266700178384781\n",
      "In epoch 935, loss: 0.11000347882509232\n",
      "In epoch 940, loss: 0.10802875459194183\n",
      "In epoch 945, loss: 0.10745323449373245\n",
      "In epoch 950, loss: 0.10428912937641144\n",
      "In epoch 955, loss: 0.10265257209539413\n",
      "In epoch 960, loss: 0.10060586780309677\n",
      "In epoch 965, loss: 0.09904637932777405\n",
      "In epoch 970, loss: 0.09635739028453827\n",
      "In epoch 975, loss: 0.09773577749729156\n",
      "In epoch 980, loss: 0.09365825355052948\n",
      "In epoch 985, loss: 0.09545298665761948\n",
      "In epoch 990, loss: 0.09288305789232254\n",
      "In epoch 995, loss: 0.09008350968360901\n",
      "In epoch 1000, loss: 0.08766381442546844\n",
      "AUC 0.8433988454886456\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(1000, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actor model\n",
    "actor = Actor(root='data/Actor', transform=NormalizeFeatures())\n",
    "train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g = create_train_test_split_edge(actor[0])\n",
    "\n",
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 16, agg='mean')\n",
    "pred = DotPredictor()\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6714571714401245\n",
      "In epoch 10, loss: 0.6475620269775391\n",
      "In epoch 15, loss: 0.6315845847129822\n",
      "In epoch 20, loss: 0.6195549964904785\n",
      "In epoch 25, loss: 0.6060764789581299\n",
      "In epoch 30, loss: 0.5928593277931213\n",
      "In epoch 35, loss: 0.580198347568512\n",
      "In epoch 40, loss: 0.5656442642211914\n",
      "In epoch 45, loss: 0.5499475598335266\n",
      "In epoch 50, loss: 0.5341180562973022\n",
      "In epoch 55, loss: 0.5176094770431519\n",
      "In epoch 60, loss: 0.5032098889350891\n",
      "In epoch 65, loss: 0.4871290326118469\n",
      "In epoch 70, loss: 0.47250697016716003\n",
      "In epoch 75, loss: 0.4589647948741913\n",
      "In epoch 80, loss: 0.4460175335407257\n",
      "In epoch 85, loss: 0.4332176148891449\n",
      "In epoch 90, loss: 0.4206375777721405\n",
      "In epoch 95, loss: 0.40838930010795593\n",
      "In epoch 100, loss: 0.3964161276817322\n",
      "AUC 0.7034637237992756\n"
     ]
    }
   ],
   "source": [
    "train_link_pred(100, model, pred, optimizer, train_g, train_pos_g, train_neg_g, test_pos_g, test_neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
