{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import to_networkx\n",
    "from copy import deepcopy\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import itertools\n",
    "import dgl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cora = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "data = cora[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of positive and negative edges\n",
    "u, v = data.edge_index.numpy()\n",
    "\n",
    "adj = coo_matrix((np.ones(data.num_edges), data.edge_index.numpy()))\n",
    "adj_neg = 1 - adj.todense() - np.eye(data.num_nodes)\n",
    "neg_u, neg_v = np.where(adj_neg != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test edge split\n",
    "test_size = int(np.floor(data.num_edges * 0.1))\n",
    "eids = np.random.permutation(np.arange(data.num_edges)) # Create an array of 'edge IDs'\n",
    "\n",
    "train_pos_u, train_pos_v = data.edge_index[:, eids[test_size:]]\n",
    "test_pos_u, test_pos_v   = data.edge_index[:, eids[:test_size]]\n",
    "\n",
    "# Sample an equal amount of negative edges from  the graph, split into train/test\n",
    "neg_eids = np.random.choice(len(neg_u), data.num_edges)\n",
    "test_neg_u, test_neg_v = (\n",
    "    neg_u[neg_eids[:test_size]],\n",
    "    neg_v[neg_eids[:test_size]],\n",
    ")\n",
    "train_neg_u, train_neg_v = (\n",
    "    neg_u[neg_eids[test_size:]],\n",
    "    neg_v[neg_eids[test_size:]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove test edges from original graph\n",
    "\n",
    "def remove_edges(G, edges):\n",
    "    G_new = deepcopy(G)\n",
    "    G_new.remove_edges_from(edges)\n",
    "    return G_new\n",
    "\n",
    "G = to_networkx(data, node_attrs=data.node_attrs())\n",
    "G_train = remove_edges(G, np.column_stack([test_pos_u, test_pos_v])) \n",
    "\n",
    "train_g = dgl.from_networkx(G_train, node_attrs=list(G.nodes[0].keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=9501,\n",
       "      ndata_schemes={'test_mask': Scheme(shape=(), dtype=torch.bool), 'y': Scheme(shape=(), dtype=torch.int64), 'x': Scheme(shape=(1433,), dtype=torch.float32), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=data.num_nodes)\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=data.num_nodes)\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=data.num_nodes)\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=data.num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "import dgl.function as fn\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, \"mean\")\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, \"mean\")\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "class DotPredictor(torch.nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata[\"h\"] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v(\"h\", \"h\", \"score\"))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata[\"score\"][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata[\"x\"].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "# pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    )\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat(\n",
    "        [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]\n",
    "    ).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 0.7107418179512024\n",
      "In epoch 5, loss: 0.6896830797195435\n",
      "In epoch 10, loss: 0.6702037453651428\n",
      "In epoch 15, loss: 0.6157683730125427\n",
      "In epoch 20, loss: 0.5559787750244141\n",
      "In epoch 25, loss: 0.515147864818573\n",
      "In epoch 30, loss: 0.4857601225376129\n",
      "In epoch 35, loss: 0.4715117812156677\n",
      "In epoch 40, loss: 0.4501242935657501\n",
      "In epoch 45, loss: 0.43352076411247253\n",
      "In epoch 50, loss: 0.4171629846096039\n",
      "In epoch 55, loss: 0.4002867043018341\n",
      "In epoch 60, loss: 0.3837142586708069\n",
      "In epoch 65, loss: 0.36696240305900574\n",
      "In epoch 70, loss: 0.3509295582771301\n",
      "In epoch 75, loss: 0.3340570032596588\n",
      "In epoch 80, loss: 0.31674373149871826\n",
      "In epoch 85, loss: 0.2993151843547821\n",
      "In epoch 90, loss: 0.28167659044265747\n",
      "In epoch 95, loss: 0.26417118310928345\n",
      "AUC 0.8575728307989489\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(\n",
    "    itertools.chain(model.parameters(), pred.parameters()), lr=0.01\n",
    ")\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "for e in range(100):\n",
    "    # forward\n",
    "    h = model(train_g, train_g.ndata[\"x\"])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "    # backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 5 == 0:\n",
    "        print(\"In epoch {}, loss: {}\".format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print(\"AUC\", compute_auc(pos_score, neg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rwn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
